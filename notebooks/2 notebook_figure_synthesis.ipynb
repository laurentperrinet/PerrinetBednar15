{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a synthesis figure\n",
    "\n",
    "In this notebook, we designed a figure to accompagny our press release, boith in french and english:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Une nouvelle étude analysant comment nous détectons un animal dans une scène visuelle permet de révéler certains mystères du cerveau.\n",
    "\n",
    "Des scientifiques de l’université d'Aix-Marseille et de l’université d'Edinburgh en Ecosse ont modélisé la façon dont nous pouvons distinguer des animaux sur une image en une fraction de seconde. Ils ont alors trouvé que cette classification est possible à un niveau de représentation très primitif, et non, comme cela est généralement admis, après une longue série d'analyses visuelles de plus en plus abstraites (détection des yeux et des membres, puis de la tête et du corps, etc...).\n",
    "\n",
    "Cette étude montre que quand des personnes regardent une image, leur cerveau se fait très rapidement une première idée de son contenu, en complément de processus de traitement de plus en plus raffinés et de plus en plus longs.\n",
    "\n",
    "Ces chercheurs ont utilisé des données précédemment enregistrées dans lesquelles des volontaires regardaient et classifiaient des centaines d'images. Ils ont ensuite utilisé desmodèles mathématiques de la représentation visuelle des images dans l'aire visuelle primaire et en particulier des inter-relations entre des éléments de contours voisins. En utilisant cette représentation primitive, ils ont mis en évidence qu'un programme très simple pouvait facilement classifier les images comme contenant ou non un animal, sans avoir\n",
    "besoin d’une connaissance plus élaborée sur les caractéristiques d’un animal comme sa position, sa taille ou son orientation sur l’image.\n",
    "\n",
    "Cette découverte peut accélérer le développement de requêtes via des images dans les moteurs de recherche, comme Google et Facebook, car elle permet une classification simple etrobuste grâce à des caractéristiques statistiques de bas niveau basées la géométrie des objets et pourrait ainsi améliorer l'efficacité de tels algorithmes.\n",
    "\n",
    "Cette étude a été financée grâce à des aides de la communauté européenne et de l'Agence Nationale pour la Recherche Française et est publiée dans le journal Scientific Reports du groupe Nature Publishing.\n",
    "\n",
    "Selon Laurent Perrinet, chercheur à l'institut des neurosciences de la Timone, qui a conduit cette étude en collaboration avec James Bednar de l'université d'Edinburgh : \"Les résultats de cette étude ont des applications directes pour la classification des images mais aussi des conséquences inattendues sur notre compréhension des mécanismes visuels. En effet, ils montrent qu'en un clin d'œil, nous sommes capables d'extraire une première impression de la scène en exploitant des régularités statistiques simples avant de procéder à une analyse plus complexe de la scène. Plus surprenant encore, nous avons mis en évidence que quand les humains se trompent en classifiant de manière erronée une image comme contenant un animal, alors le modèle que nous avons construit se trompe de la même façon!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:36.663108Z",
     "start_time": "2018-07-17T08:49:36.651556Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:36.673913Z",
     "start_time": "2018-07-17T08:49:36.664571Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd -q ../test/\n",
    "import os\n",
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:36.905902Z",
     "start_time": "2018-07-17T08:49:36.675572Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") # agg-backend, so we can create figures without x-server (no PDF, just PNG etc.)\n",
    "#matplotlib.rcParams.update({'font.size': 18, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
    "matplotlib.rcParams.update({'text.usetex': True})\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format='retina'\n",
    "%config InlineBackend.figure_format='svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)#, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one tiger of an image\n",
    "\n",
    "The image was imported in the database notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:36.920819Z",
     "start_time": "2018-07-17T08:49:36.907582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting experiment_yelmo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile experiment_yelmo.py\n",
    "\n",
    "import numpy as np\n",
    "from SparseEdges import SparseEdges\n",
    "\n",
    "#ef = SparseEdges('https://raw.githubusercontent.com/bicv/SparseEdges/master/default_param.py')\n",
    "mp = SparseEdges('../notebooks/srep_param.py')\n",
    "\n",
    "mp.pe.figpath = '../figures'\n",
    "mp.pe.N = 2048\n",
    "mp.pe.MP_alpha = .9\n",
    "\n",
    "# defining input image\n",
    "#image = mp.imread('https://raw.githubusercontent.com/bicv/SparseEdges/master/database/yelmo256.png')\n",
    "image = mp.imread('../database/6370387703_5e718ea681_q_d.jpg')\n",
    "mp.set_size(image)\n",
    "\n",
    "mp.init()\n",
    "white = mp.pipeline(image, do_whitening=True)\n",
    "\n",
    "\n",
    "name = 'MPtutorial'\n",
    "import os\n",
    "matname = os.path.join(mp.pe.matpath, name + '.npy')\n",
    "try:\n",
    "    edges = np.load(matname)\n",
    "except Exception:\n",
    "    edges, C_res = mp.run_mp(white, verbose=True)\n",
    "    np.save(matname, edges)    \n",
    "\n",
    "fig_width_pt = 318.670  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "mp.pe.figsize_edges = 9 #.382 * fig_width\n",
    "mp.pe.line_width = 3.\n",
    "mp.pe.scale = .5\n",
    "\n",
    "\n",
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(white), show_phase=False, show_mask=True)\n",
    "mp.savefig(fig, name, figpath=None)\n",
    "\n",
    "image_rec = mp.reconstruct(edges, do_mask=True)        \n",
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(image_rec), show_phase=False, show_mask=True)\n",
    "mp.savefig(fig, name + '_rec', figpath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.654Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run experiment_yelmo.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%rm {matname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chevron plot animal vs non-animal (french)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the ``3 notebook_figure_chevrons`` notebook before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.671Z"
    }
   },
   "outputs": [],
   "source": [
    "%run experiment_hists.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.729Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "fig_width_pt = 265. # Get this from LaTeX using \\showthe\\columnwidth\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "\n",
    "ef.pe.figpath = '../figures'\n",
    "\n",
    "\n",
    "figsize3 = (fig_width, fig_width)\n",
    "\n",
    "print(' figure : chevron map ')\n",
    "dolog = False\n",
    "dolog = True\n",
    "half = True\n",
    "half = False\n",
    "labels = False\n",
    "labels = True\n",
    "fig = plt.figure(figsize=figsize3)\n",
    "border = 0.03\n",
    "\n",
    "#              *left*, *bottom*, *width*, *height*\n",
    "compare = False\n",
    "ax = fig.add_axes((border*5, border, 1.-border*4, 1.-border), facecolor='w')\n",
    "xticks=True\n",
    "ax.axis(c='b', lw=0)\n",
    "#     v_max, v_min = 2., -1.\n",
    "v_max, v_min = None, None\n",
    "if compare:\n",
    "    v_hist_angle = v_hist2.sum(axis=(0, 3)).mean(axis=-1) / v_hist1.sum(axis=(0, 3)).mean(axis=-1) # -d-, phi, theta, -scale-\n",
    "    print (' Figure 3 : maximum of animal vs non-animal map is ', v_hist_angle.max()/v_hist_angle.mean(), ' minimum is ', v_hist_angle.min()/v_hist_angle.mean())\n",
    "    v_max, v_min = .19, -1.\n",
    "    fig, ax = ef.cohistedges(edgeslist=None, v_hist=v_hist2.mean(axis=-1), prior=v_hist1.mean(axis=-1), v_min=v_min, v_max=v_max,\n",
    "                        fig=fig, ax=ax, display='chevrons', dolog=dolog, labels=labels, xticks=xticks, half=half, cbar_label=False)\n",
    "else:\n",
    "    fig, ax = ef.cohistedges(edgeslist=None, v_hist=v_hist1.mean(axis=-1), v_min=v_min, v_max=v_max,\n",
    "                        fig=fig, ax=ax, display='chevrons', dolog=dolog, labels=labels, xticks=xticks, half=half, cbar_label=False)\n",
    "\n",
    "# FRENCH\n",
    "if compare: \n",
    "    _ = ax.set_title(r'Catégorie animal par rapport \\`a non-animal', fontsize=10)\n",
    "else:\n",
    "    _ = ax.set_title(r'Images naturelles', fontsize=10)\n",
    "_ = ax.set_xlabel(r\"Différence d'azimuth $\\psi$\", fontsize=10)\n",
    "_ = ax.set_ylabel(r\"Différence d'orientation $\\theta$\", fontsize=10)\n",
    "ef.savefig(fig, 'figure_chevrons_animals_FR', figpath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.739Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if compare: _ = ax.set_title(r'Animal versus non-animal images', fontsize=10)\n",
    "else:\n",
    "    _ = ax.set_title(r'Chevron map over natural images', fontsize=10)\n",
    "_ = ax.set_xlabel(r\"Azimuth difference $\\psi$\", fontsize=10)\n",
    "_ = ax.set_ylabel(r\"Orientation difference $\\theta$\", fontsize=10)\n",
    "\n",
    "ef.savefig(fig, 'figure_chevrons_animals', figpath=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montage of the 2 subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.741Z"
    }
   },
   "outputs": [],
   "source": [
    "import tikzmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.742Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.743Z"
    }
   },
   "outputs": [],
   "source": [
    "%cp ../figures/MPtutorial_rec.pdf ../figures/diagram.pdf  ../figures/figure_chevrons_animals.pdf ../figures/figure_chevrons_animals_FR.pdf /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.745Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%tikz \n",
    "\n",
    "\n",
    "\\draw [anchor=north west] (0, 5) node {\\includegraphics[width=5cm]{/tmp/MPtutorial_rec.pdf}};\n",
    "\\draw [anchor=north west] (5, 5) node {\\includegraphics[width=3cm]{/tmp/diagram.pdf}};\n",
    "\\draw [anchor=north west] (5, 3) node {\\includegraphics[width=3cm]{/tmp/figure_chevrons_animals.pdf}};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.746Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%tikz -l arrows.meta -S ../figures/figure_synthesis.pdf\n",
    "\n",
    "\\draw [anchor=north west] (0, 5) node {\\reflectbox{\\includegraphics[width=3cm]{/tmp/MPtutorial_rec.pdf}}};\n",
    "\n",
    "\\draw (.85, 4.15) rectangle (1.25, 4.35);\n",
    "\n",
    "\\draw [anchor=north west] (0, 2) node {\\includegraphics[width=2.8cm]{/tmp/diagram.pdf}};\n",
    "\n",
    "\\draw [-{Stealth[length=2mm]}, thick, blue!65] (.85, 4.15) --  (0.15, 1.85);\n",
    "\\draw [-{Stealth[length=2mm]}, thick, blue!65] (1.25, 4.15) --  (3.1, 1.85);\n",
    "\\draw [thick, blue!65] (0.15, 0) rectangle (3.1, 1.85);\n",
    "\n",
    "\n",
    "\\draw [anchor=north west] (3.2, 5.5) node {\\includegraphics[width=6cm]{/tmp/figure_chevrons_animals.pdf}};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%tikz -l arrows.meta -S ../figures/figure_synthesis_FR.pdf\n",
    "\n",
    "\\draw [anchor=north west] (0, 5) node {\\reflectbox{\\includegraphics[width=3cm]{/tmp/MPtutorial_rec.pdf}}};\n",
    "\n",
    "\\draw (.85, 4.15) rectangle (1.25, 4.35);\n",
    "\n",
    "\\draw [anchor=north west] (0, 2) node {\\includegraphics[width=2.8cm]{/tmp/diagram.pdf}};\n",
    "\n",
    "\\draw [-{Stealth[length=2mm]}, thick, blue!65] (.85, 4.15) --  (0.15, 1.85);\n",
    "\\draw [-{Stealth[length=2mm]}, thick, blue!65] (1.25, 4.15) --  (3.1, 1.85);\n",
    "\\draw [thick, blue!65] (0.15, 0) rectangle (3.1, 1.85);\n",
    "\n",
    "\n",
    "\\draw [anchor=north west] (3.2, 5.5) node {\\includegraphics[width=6cm]{/tmp/figure_chevrons_animals_FR.pdf}};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir d'une image naturelle (en haut à gauche), les auteurs de cette étude ont déterminé la façon la plus efficace de la réprésenter comme une succession de contours élémentaires orientés. Sur cette exemple, l'image est déomposée en contours élémentaires (marqués en rouge) et l'image correspond à sa reconstruction à partir de cette représentation, gage d'un représentation correcte de l'image. Le schéma (en bas à gauche) décrit alors les relations géométriques pour chaque paire de contours élémentaires (dénotés ici A et B) et en particulier la différence entre leurs orientations (cette différence est nulle pour des contours parallèles) ainsi que leur différence d'azimuth. Une valeur nulle de cette dernière indiquant une symétrie, c'est-à-dire que ces contours sont co-circulaires. On peut alors compiler les statistiques des différentes configurations possibles sur des bases de données de 600 images contenant et 600 ne contenant pas d'animal. On voit alors que les images contenant un animal présentent relativement moins de configurations parallèles (disques bleus, jusqu'à 50% de moins) et plus de configurations co-circulaires, c'est à dire le long de l'axe vertical médian (disques rouges, jusqu'à 20% d'occurences en plus). Cette différence, aussi tenue soit elle permet alors de classifier une image pour permettre de deviner si elle contient ou non un animal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.749Z"
    }
   },
   "outputs": [],
   "source": [
    "!convert -density 600 ../figures/figure_synthesis.pdf  ../figures/figure_synthesis.png\n",
    "!convert -density 600 ../figures/figure_synthesis_FR.pdf  ../figures/figure_synthesis_FR.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.750Z"
    }
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.751Z"
    }
   },
   "outputs": [],
   "source": [
    "#!git add ../figures/figure_synthesis* ../figures/figure_chevrons_animals* ../database/6370387703_5e718ea681_q_d.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-17T08:49:36.752Z"
    }
   },
   "outputs": [],
   "source": [
    "!git commit -m' re-launching notebooks : figure synthesis' ../notebooks/2\\ notebook_figure_synthesis.ipynb ../figures/figure_synthesis* \n",
    "#! git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
