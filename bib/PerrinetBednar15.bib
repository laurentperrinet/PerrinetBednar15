@article{Li02,
    abstract = {What can we see when we do not pay attention? It is well known that we can be  ” blind” even to major aspects of natural scenes when we attend elsewhere. The only tasks that do not need attention appear to be carried out in the early stages of the visual system. Contrary to this common belief, we report that subjects can rapidly detect animals or vehicles in briefly presented novel natural scenes while simultaneously performing another attentionally demanding task. By comparison, they are unable to discriminate large T's from L's, or bisected two-color disks from their mirror images under the same conditions. We conclude that some visual tasks associated with  ” high-level” cortical areas may proceed in the near absence of attention.},
    author = {Li, Fei F. and VanRullen, Rufin and Koch, Christof and Perona, Pietro},
    citeulike-article-id = {967484},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.092277599},
    citeulike-linkout-1 = {http://www.pnas.org/content/99/14/9596.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/99/14/9596.full.pdf},
    citeulike-linkout-3 = {http://www.pnas.org/cgi/content/abstract/99/14/9596},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/12077298},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=12077298},
    date-added = {2015-02-04 22:08:30},
    day = {09},
    doi = {10.1073/pnas.092277599},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, attention, ultra-rapid\_categorization},
    month = jul,
    number = {14},
    pages = {9596--9601},
    pmid = {12077298},
    priority = {3},
    publisher = {National Academy of Sciences},
    title = {Rapid natural scene categorization in the near absence of attention},
    url = {http://dx.doi.org/10.1073/pnas.092277599},
    volume = {99},
    year = {2002}
}

@article{Wichmann06,
    abstract = {We measured the effect of global phase manipulations on a rapid animal categorization task. The Fourier spectra of our images of natural scenes were manipulated by adding zero-mean random phase noise at all spatial frequencies. The phase noise was the independent variable, uniformly and symmetrically distributed between 0 degrees and +/-180 degrees . Subjects were remarkably resistant to phase noise. Even with +/-120 degrees phase noise subjects were still performing at 75\% correct. The high resistance of the subjects' animal categorization rate to phase noise suggests that the visual system is highly robust to such random image changes. The proportion of correct answers closely followed the correlation between original and the phase noise-distorted images. Animal detection rate was higher when the same task was performed with contrast reduced versions of the same natural images, at contrasts where the contrast reduction mimicked that resulting from our phase randomization. Since the subjects' categorization rate was better in the contrast experiment, reduction of local contrast alone cannot explain the performance in the phase noise experiment. This result obtained with natural images differs from those obtained for simple sinusoidal stimuli were performance changes due to phase changes are attributed to local contrast changes only. Thus the global phase-change accompanying disruption of image structure such as edges and object boundaries at different spatial scales reduces object classification over and above the performance deficit resulting from reducing contrast. Additional color information improves the categorization performance by 2\%.},
    author = {Wichmann, Felix A. and Braun, Doris I. and Gegenfurtner, Karl R.},
    citeulike-article-id = {6496886},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.visres.2005.11.008},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16384589},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16384589},
    date-added = {2015-02-02 10:34:22},
    doi = {10.1016/j.visres.2005.11.008},
    issn = {00426989},
    journal = {Vision Research},
    keywords = {assofield},
    month = apr,
    number = {8-9},
    pages = {1520--1529},
    pmid = {16384589},
    priority = {0},
    title = {Phase noise and the classification of natural images},
    url = {http://dx.doi.org/10.1016/j.visres.2005.11.008},
    volume = {46},
    year = {2006}
}

@article{Siagian06,
    author = {Siagian, Christian and Itti, Laurent},
    citeulike-article-id = {2055225},
    citeulike-linkout-0 = {http://ilab.usc.edu/publications/doc/Siagian\_Itti07pami.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2007.40},
    date-added = {2015-01-08 15:24:49},
    doi = {10.1109/TPAMI.2007.40},
    issn = {0162-8828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {assofield, ultra-rapid\_categorization},
    month = feb,
    number = {2},
    pages = {300--312},
    priority = {0},
    title = {Rapid {Biologically-Inspired} Scene Classification Using Features Shared with Visual Attention},
    url = {http://ilab.usc.edu/publications/doc/Siagian\_Itti07pami.pdf},
    volume = {29},
    year = {2007}
}

@article{Drewes11,
    abstract = {Human observers are capable of detecting animals within novel natural scenes with remarkable speed and accuracy. Recent studies found human response times to be as fast as 120 ms in a dual-presentation ({2-AFC}) setup (H. Kirchner \& S. J. Thorpe, 2005). In most previous experiments, pairs of randomly chosen images were presented, frequently from very different contexts (e.g., a zebra in Africa vs. the New York Skyline). Here, we tested the effect of background size and contiguity on human performance by using a new, contiguous background image set. Individual images contained a single animal surrounded by a large, animal-free image area. The image could be positioned and cropped in such a manner that the animal could occur in one of eight evenly spaced positions on an imaginary circle (radius 10-deg visual angle). In the first ({8-Choice}) experiment, all eight positions were used, whereas in the second ({2-Choice}) and third ({2-Image}) experiments, the animals were only presented on the two positions to the left and right of the screen center. In the third experiment, additional rectangular frames were used to mimic the conditions of earlier studies. Average latencies on successful trials differed only slightly between conditions, indicating that the number of possible animal locations within the display does not affect decision latency. Detailed analysis of saccade targets revealed a preference toward both the head and the center of gravity of the target animal, affecting hit ratio, latency, and the number of saccades required to reach the target. These results illustrate that rapid animal detection operates scene-wide and is fast and efficient even when the animals are embedded in their natural backgrounds.},
    author = {Drewes, J. and Trommershauser, J. and Gegenfurtner, K. R.},
    citeulike-article-id = {13463616},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/11.2.20},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/11/2/20.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/11/2/20.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/21367757},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=21367757},
    date-added = {2014-12-18 08:44:18},
    day = {25},
    doi = {10.1167/11.2.20},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {animals, assofield, saliency, ultra-rapid\_categorization, visual-search},
    month = feb,
    number = {2},
    pages = {20},
    pmid = {21367757},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Parallel visual search and rapid animal detection in natural scenes},
    url = {http://dx.doi.org/10.1167/11.2.20},
    volume = {11},
    year = {2011}
}

@article{Elder09,
    abstract = {Humans are known to be good at rapidly detecting animals in natural scenes. Evoked potential studies indicate that the corresponding neural signals can emerge in the brain within 150 msec of stimulus onset (S. Thorpe, D. Fize, \& C. Marlot, 1996) and eye movements toward animal targets can be initiated in roughly the same timeframe (H. Kirchner \& S. J. Thorpe, 2006). Given the speed of this discrimination, it has been suggested that the underlying visual mechanisms must be relatively simple and feedforward, but in fact little is known about these mechanisms. A key step is to understand the visual cues upon which these mechanisms rely. Here we investigate the role and dynamics of four potential cues: two-dimensional boundary shape, texture, luminance, and color. Results suggest that the fastest mechanisms underlying animal detection in natural scenes use shape as a principal discriminative cue, while somewhat slower mechanisms integrate these rapidly computed shape cues with image texture cues. Consistent with prior studies, we find little role for luminance and color cues throughout the time course of visual processing, even though information relevant to the task is available in these signals.},
    author = {Elder, James H. and Velisavljevi\'{c}, Ljiljana},
    citeulike-article-id = {6486452},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/9.7.7},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/9/7/7.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/9/7/7.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/19761322},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=19761322},
    date-added = {2014-11-19 21:46:52},
    day = {10},
    doi = {10.1167/9.7.7},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, ultra-rapid\_categorization},
    month = jul,
    number = {7},
    pages = {7--20},
    pmid = {19761322},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Cue dynamics underlying rapid detection of animals in natural scenes},
    url = {http://dx.doi.org/10.1167/9.7.7},
    volume = {9},
    year = {2009}
}

@article{Hughes2014Striperearing,
    author = {Hughes, Nicholas J. and Hunt, Jonathan J. and Cloherty, Shaun L. and Ibbotson, Michael R. and Sengpiel, Frank and Goodhill, Geoffrey J.},
    citeulike-article-id = {13390415},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.neuroimage.2014.03.031},
    date-added = {2014-10-13 21:12:01},
    doi = {10.1016/j.neuroimage.2014.03.031},
    issn = {10538119},
    journal = {NeuroImage},
    keywords = {area-v1, assofield},
    month = jul,
    pages = {305--319},
    priority = {5},
    title = {Stripe-rearing changes multiple aspects of the structure of primary visual cortex},
    url = {http://dx.doi.org/10.1016/j.neuroimage.2014.03.031},
    volume = {95},
    year = {2014}
}

@article{PerrinetBednar14vss,
    abstract = {Analysis and interpretation of a visual scene to extract its category, such as whether it contains an animal, is typically assumed to involve higher-level associative brain areas. Previous proposals have been based on a series of processing steps organized in a multi-level hierarchy that would progressively analyze the scene at increasing levels of abstraction, from contour extraction to low-level object recognition and finally to object categorization (Serre, {PNAS} 2007). We explore here an alternative hypothesis that the statistics of edge co-occurences are sufficient to perform a rough yet robust (translation, scale, and rotation invariant) scene categorization. The method is based on a realistic model of image analysis in the primary visual cortex that extends previous work from Geisler et al. (Vis. Res. 2001). Using a scale-space analysis coupled with a sparse coding algorithm, we achieved detailed and robust extraction of edges in different sets of natural images. This edge-based representation allows for a simple characterization of the ``association field'' of edges by computing the statistics of co-occurrences. We show that the geometry of angles made between edges is sufficient to distinguish between different sets of natural images taken in a variety of environments (natural, man-made, or containing an animal). Specifically, a simple classifier, working solely on the basis of this geometry, gives performance similar to that of hierarchical models and of humans in rapid-categorization tasks. Such results call attention to the importance of the relative geometry of local image patches in visual computation, with implications for designing efficient image analysis systems. Most importantly, they challenge assumptions about the flow of computations in the visual system and emphasize the relative importance in this process of associative connections, and in particular of intra-areal lateral connections.},
    author = {Perrinet, Laurent U. and Bednar, James A.},
    citeulike-article-id = {13342391},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/14.10.1310},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/14/10/1310.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/14/10/1310.full.pdf},
    date-added = {2014-09-01 09:23:53},
    day = {22},
    doi = {10.1167/14.10.1310},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield},
    month = aug,
    number = {10},
    pages = {1310},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Edge co-occurrences are sufficient to categorize natural versus animal images},
    url = {http://dx.doi.org/10.1167/14.10.1310},
    volume = {14},
    year = {2014}
}

@article{Rice14,
    abstract = {Neuroimaging studies have revealed strong selectivity for object categories in high-level regions of the human visual system. However, it is unknown whether this selectivity is truly based on object category, or whether it reflects tuning for low-level features that are common to images from a particular category. To address this issue, we measured the neural response to different object categories across the ventral visual pathway. Each object category elicited a distinct neural pattern of response. Next, we compared the patterns of neural response between object categories. We found a strong positive correlation between the neural patterns and the underlying low-level image properties. Importantly, this correlation was still evident when the within-category correlations were removed from the analysis. Next, we asked whether basic image properties could also explain variation in the pattern of response to different exemplars from one object category (faces). A significant correlation was also evident between the similarity of neural patterns of response and the low-level properties of different faces, particularly in regions associated with face processing. These results suggest that the appearance of category-selective regions at this coarse scale of representation may be explained by the systematic convergence of responses to low-level features that are characteristic of each category. Copyright {\copyright} 2014 Rice et al.},
    author = {Rice, G. E. and Watson, D. M. and Hartley, T. and Andrews, T. J.},
    citeulike-article-id = {13243312},
    citeulike-linkout-0 = {http://dx.doi.org/10.1523/jneurosci.5265-13.2014},
    citeulike-linkout-1 = {http://www.jneurosci.org/content/34/26/8837.abstract},
    citeulike-linkout-2 = {http://www.jneurosci.org/content/34/26/8837.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24966383},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24966383},
    date-added = {2014-06-26 14:32:03},
    day = {25},
    doi = {10.1523/jneurosci.5265-13.2014},
    issn = {1529-2401},
    journal = {Journal of Neuroscience},
    keywords = {assofield, categorization, natural-scenes},
    month = jun,
    number = {26},
    pages = {8837--8844},
    pmid = {24966383},
    priority = {2},
    publisher = {Society for Neuroscience},
    title = {Low-level image properties of visual objects predict patterns of neural response across category-selective regions of the ventral visual pathway.},
    url = {http://dx.doi.org/10.1523/jneurosci.5265-13.2014},
    volume = {34},
    year = {2014}
}

@article{Dumoulin14,
    abstract = {Neurons in the visual cortex process a local region of visual space, but in order to adequately analyze natural images, neurons need to interact. The notion of an  ” association field” proposes that neurons interact to extract extended contours. Here, we identify the site and properties of contour integration mechanisms. We used functional magnetic resonance imaging ({fMRI}) and population receptive field ({pRF}) analyses. We devised {pRF} mapping stimuli consisting of contours. We isolated the contribution of contour integration mechanisms to the {pRF} by manipulating the contour content. This stimulus manipulation led to systematic changes in {pRF} size. Whereas a bank of Gabor filters quantitatively explains {pRF} size changes in V1, only {V2/V3} {pRF} sizes match the predictions of the association field. {pRF} size changes in later visual field maps, {hV4}, {LO}-1, and {LO}-2 do not follow either prediction and are probably driven by distinct classical receptive field properties or other extraclassical integration mechanisms. These {pRF} changes do not follow conventional {fMRI} signal strength measures. Therefore, analyses of {pRF} changes provide a novel computational neuroimaging approach to investigating neural interactions. We interpreted these results as evidence for neural interactions along co-oriented, cocircular receptive fields in the early extrastriate visual cortex ({V2/V3}), consistent with the notion of a contour association field.},
    author = {Dumoulin, Serge O. and Hess, Robert F. and May, Keith A. and Harvey, Ben M. and Rokers, Bas and Barendregt, Martijn},
    citeulike-article-id = {13243184},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/14.5.18},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/14/5/18.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/14/5/18.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24879865},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24879865},
    date-added = {2014-06-26 12:05:27},
    day = {30},
    doi = {10.1167/14.5.18},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, bicv-sparse, contour, natural-scenes},
    month = may,
    number = {5},
    pages = {18+},
    pmid = {24879865},
    priority = {3},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Contour extracting networks in early extrastriate cortex},
    url = {http://dx.doi.org/10.1167/14.5.18},
    volume = {14},
    year = {2014}
}

@article{Epshtein08,
    abstract = {The human visual system recognizes objects and their constituent parts rapidly and with high accuracy. Standard models of recognition by the visual cortex use feed-forward processing, in which an object's parts are detected before the complete object. However, parts are often ambiguous on their own and require the prior detection and localization of the entire object. We show how a cortical-like hierarchy obtains recognition and localization of objects and parts at multiple levels nearly simultaneously by a single feed-forward sweep from low to high levels of the hierarchy, followed by a feedback sweep from high- to low-level areas.},
    author = {Epshtein, Boris and Lifshitz, Ita and Ullman, Shimon},
    citeulike-article-id = {3332720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.0800968105},
    citeulike-linkout-1 = {http://www.pnas.org/content/105/38/14298.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/105/38/14298.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/18796607},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=18796607},
    date-added = {2014-06-26 08:59:41},
    day = {23},
    doi = {10.1073/pnas.0800968105},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, categorization, natural-scenes},
    month = sep,
    number = {38},
    pages = {14298--14303},
    pmid = {18796607},
    priority = {2},
    publisher = {National Academy of Sciences},
    title = {Image interpretation by a single bottom-up top-down cycle},
    url = {http://dx.doi.org/10.1073/pnas.0800968105},
    volume = {105},
    year = {2008}
}

@article{Singer14,
    abstract = {Humans can recognize objects and scenes in a small fraction of a second. The cascade of signals underlying rapid recognition might be disrupted by temporally jittering different parts of complex objects. Here we investigated the time course over which shape information can be integrated to allow for recognition of complex objects. We presented fragments of object images in an asynchronous fashion and behaviorally evaluated categorization performance. We observed that visual recognition was significantly disrupted by asynchronies of approximately 30 ms, suggesting that spatiotemporal integration begins to break down with even small deviations from simultaneity. However, moderate temporal asynchrony did not completely obliterate recognition; in fact, integration of visual shape information persisted even with an asynchrony of 100 ms. We describe the data with a concise model based on the dynamic reduction of uncertainty about what image was presented. These results emphasize the importance of timing in visual processing and provide strong constraints for the development of dynamical models of visual shape recognition.},
    author = {Singer, Jedediah M. and Kreiman, Gabriel},
    citeulike-article-id = {13200835},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/14.5.7},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/14/5/7.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/14/5/7.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24819738},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24819738},
    date-added = {2014-05-26 20:33:53},
    day = {12},
    doi = {10.1167/14.5.7},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, asynchrony, visual\_object\_recognition},
    month = may,
    number = {5},
    pages = {7+},
    pmid = {24819738},
    priority = {5},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Short temporal asynchrony disrupts visual object recognition},
    url = {http://dx.doi.org/10.1167/14.5.7},
    volume = {14},
    year = {2014}
}

@article{Nasr14,
    abstract = {Fifteen years ago, an intriguing area was found in human visual cortex. This area (the parahippocampal place area [{PPA}]) was initially interpreted as responding selectively to images of places. However, subsequent studies reported that {PPA} also responds strongly to a much wider range of image categories, including inanimate objects, tools, spatial context, landmarks, objectively large objects, indoor scenes, and/or isolated buildings. Here, we hypothesized that {PPA} responds selectively to a lower-level stimulus property (rectilinear features), which are common to many of the above higher-order categories. Using a novel wavelet image filter, we first demonstrated that rectangular features are common in these diverse stimulus categories. Then we tested whether {PPA} is selectively activated by rectangular features in six independent {fMRI} experiments using progressively simplified stimuli, from complex real-world images, through {3D}/{2D} computer-generated shapes, through simple line stimuli. We found that {PPA} was consistently activated by rectilinear features, compared with curved and nonrectangular features. This rectilinear preference was (1) comparable in amplitude and selectivity, relative to the preference for category (scenes vs faces), (2) independent of known biases for specific orientations and spatial frequency, and (3) not predictable from V1 activity. Two additional scene-responsive areas were sensitive to a subset of rectilinear features. Thus, rectilinear selectivity may serve as a crucial building block for category-selective responses in {PPA} and functionally related areas.},
    author = {Nasr, Shahin and Echavarria, Cesar E. and Tootell, Roger B. H.},
    citeulike-article-id = {13176971},
    citeulike-linkout-0 = {http://dx.doi.org/10.1523/jneurosci.4802-13.2014},
    citeulike-linkout-1 = {http://www.jneurosci.org/content/34/20/6721.abstract},
    citeulike-linkout-2 = {http://www.jneurosci.org/content/34/20/6721.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24828628},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24828628},
    date-added = {2014-05-20 18:00:59},
    day = {14},
    doi = {10.1523/jneurosci.4802-13.2014},
    issn = {1529-2401},
    journal = {The Journal of Neuroscience},
    keywords = {assofield, categorization, natural-scenes},
    month = may,
    number = {20},
    pages = {6721--6735},
    pmid = {24828628},
    priority = {5},
    publisher = {Society for Neuroscience},
    title = {Thinking Outside the Box: Rectilinear Shapes Selectively Activate {Scene-Selective} Cortex},
    url = {http://dx.doi.org/10.1523/jneurosci.4802-13.2014},
    volume = {34},
    year = {2014}
}

@article{Bauer14,
    abstract = {Injections of neural tracers into many mammalian neocortical areas reveal a common patchy motif of clustered axonal projections. We studied in simulation a mathematical model for neuronal development in order to investigate how this patchy connectivity could arise in layer {II}/{III} of the neocortex. In our model, individual neurons of this layer expressed the activator-inhibitor components of a {Gierer-Meinhardt} reaction-diffusion system. The resultant steady-state reaction-diffusion pattern across the neuronal population was approximately hexagonal. Growth cones at the tips of extending axons used the various morphogens secreted by intrapatch neurons as guidance cues to direct their growth and invoke axonal arborization, so yielding a patchy distribution of arborization across the entire layer {II}/{III}. We found that adjustment of a single parameter yields the intriguing linear relationship between average patch diameter and interpatch spacing that has been observed experimentally over many cortical areas and species. We conclude that a simple {Gierer-Meinhardt} system expressed by the neurons of the developing neocortex is sufficient to explain the patterns of clustered connectivity observed experimentally.},
    author = {Bauer, Roman and Zubler, Frederic and Hauri, Andreas and Muir, Dylan R. and Douglas, Rodney J.},
    citeulike-article-id = {13132341},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/23131803},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=23131803},
    date-added = {2014-04-10 09:42:33},
    issn = {1460-2199},
    journal = {Cerebral cortex (New York, N.Y. : 1991)},
    keywords = {assofield, lateral\_connections, patch-based},
    month = feb,
    number = {2},
    pages = {487--500},
    pmid = {23131803},
    priority = {4},
    title = {Developmental origin of patchy axonal connectivity in the neocortex: a computational model.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/23131803},
    volume = {24},
    year = {2014}
}

@inproceedings{Rudiger14cosyne,
    author = {Rudiger, Philipp P. and Stevens, Jean-Luc and Talluri, Bharath C. and Perrinet, Laurent and Bednar, James},
    booktitle = {Proceedings of COSYNE},
    citeulike-article-id = {13131445},
    citeulike-linkout-0 = {http://invibe.net/LaurentPerrinet/Publications/Rudiger14cosyne},
    date-added = {2014-04-09 10:27:44},
    keywords = {assofield, motion},
    priority = {0},
    title = {Relationship between natural image statistics and lateral connectivity in the primary visual cortex},
    url = {http://invibe.net/LaurentPerrinet/Publications/Rudiger14cosyne},
    year = {2014}
}

@article{Geisler1999Motion,
    author = {Geisler, Wilson S.},
    citeulike-article-id = {13122685},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/21886},
    comment = {10.1038/21886},
    date-added = {2014-04-01 14:18:31},
    day = {1},
    doi = {10.1038/21886},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {assofield, motion},
    month = jul,
    number = {6739},
    pages = {65--69},
    priority = {5},
    publisher = {Macmillan Magazines Ltd.},
    title = {Motion streaks provide a spatial code for motion direction},
    url = {http://dx.doi.org/10.1038/21886},
    volume = {400},
    year = {1999}
}

@article{Cichy14,
    abstract = {A comprehensive picture of object processing in the human brain requires combining both spatial and temporal information about brain activity. Here we acquired human magnetoencephalography ({MEG}) and functional magnetic resonance imaging ({fMRI}) responses to 92 object images. Multivariate pattern classification applied to {MEG} revealed the time course of object processing: whereas individual images were discriminated by visual representations early, ordinate and superordinate category levels emerged relatively late. Using representational similarity analysis, we combined human {fMRI} and {MEG} to show content-specific correspondence between early {MEG} responses and primary visual cortex (V1), and later {MEG} responses and inferior temporal ({IT}) cortex. We identified transient and persistent neural activities during object processing with sources in V1 and {IT}. Finally, we correlated human {MEG} signals to single-unit responses in monkey {IT}. Together, our findings provide an integrated space- and time-resolved view of human object categorization during the first few hundred milliseconds of vision.},
    author = {Cichy, Radoslaw M. and Pantazis, Dimitrios and Oliva, Aude},
    citeulike-article-id = {13075361},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.3635},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.3635},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/24464044},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=24464044},
    date-added = {2014-03-18 13:09:19},
    day = {26},
    doi = {10.1038/nn.3635},
    issn = {1097-6256},
    journal = {Nature Neuroscience},
    keywords = {assofield, categorization, fmri, meg},
    month = jan,
    number = {3},
    pages = {455--462},
    pmid = {24464044},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Resolving human object recognition in space and time},
    url = {http://dx.doi.org/10.1038/nn.3635},
    volume = {17},
    year = {2014}
}

@article{Mur14,
    abstract = {A study shows the transience of early visual representations (while the stimulus is still on) and the persistence of higher representations (outlasting the stimulus) as various categorical distinctions emerge at staggered latencies. Rather than slavishly following the stimulus, representations interact through recurrent signals to infer what's there.},
    author = {Mur, Marieke and Kriegeskorte, Nikolaus},
    citeulike-article-id = {13075371},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.3661},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.3661},
    date-added = {2014-03-18 13:08:35},
    day = {25},
    doi = {10.1038/nn.3661},
    issn = {1097-6256},
    journal = {Nat Neurosci},
    keywords = {assofield, categorization},
    month = mar,
    number = {3},
    pages = {332--333},
    priority = {0},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {What's there, distinctly, when and where?},
    url = {http://dx.doi.org/10.1038/nn.3661},
    volume = {17},
    year = {2014}
}

@article{Potter13,
    abstract = {The visual system is exquisitely adapted to the task of extracting conceptual information from visual input with every new eye fixation, three or four times a second. Here we assess the minimum viewing time needed for visual comprehension, using rapid serial visual presentation ({RSVP}) of a series of six or 12 pictures presented at between 13 and 80 ms per picture, with no interstimulus interval. Participants were to detect a picture specified by a name (e.g., smiling couple) that was given just before or immediately after the sequence. Detection improved with increasing duration and was better when the name was presented before the sequence, but performance was significantly above chance at all durations, whether the target was named before or only after the sequence. The results are consistent with feedforward models, in which an initial wave of neural activity through the ventral stream is sufficient to allow identification of a complex visual stimulus in a single forward pass. Although we discuss other explanations, the results suggest that neither reentrant processing from higher to lower levels nor advance information about the stimulus is necessary for the conscious detection of rapidly presented, complex visual information.},
    author = {Potter, MaryC and Wyble, Brad and Hagmann, CarlErick and McCourt, EmilyS},
    booktitle = {Attention, Perception, \& Psychophysics},
    citeulike-article-id = {12936346},
    citeulike-linkout-0 = {http://dx.doi.org/10.3758/s13414-013-0605-z},
    citeulike-linkout-1 = {http://link.springer.com/article/10.3758/s13414-013-0605-z},
    date-added = {2014-01-25 14:21:03},
    doi = {10.3758/s13414-013-0605-z},
    keywords = {assofield, ultra-rapid\_categorization},
    pages = {1--10},
    priority = {4},
    publisher = {Springer US},
    title = {Detecting meaning in {RSVP} at 13 ms per picture},
    url = {http://dx.doi.org/10.3758/s13414-013-0605-z},
    year = {2013}
}

@article{Hegde08,
    abstract = {Our perception of a visual scene changes rapidly in time, even when the scene itself does not. It is increasingly clear that understanding how the visual percept changes in time is crucial to understanding how we see. We are still far from fully understanding the temporal changes in the visual percept and the neural mechanisms that underlie it. But recently, many disparate lines of evidence are beginning to converge to produce a complex but fuzzy picture of visual temporal dynamics. It is clear, largely from psychophysical studies in humans, that one can get the 'gist' of complex visual scenes within about 150ms after the stimulus onset, even when the stimulus itself is presented as briefly as 10 ms or so. It generally takes longer processing, if not longer stimulus presentation, to identify individual objects. It may take even longer for a fuller semantic understanding, or awareness, of the scene to emerge and be encoded in short-term memory. Microelectrode recording studies in monkeys, along with neuroimaging studies mostly in humans, have elucidated many important temporal dynamic phenomena at the level of individual neurons and neuronal populations. Many of the temporal changes at the perceptual and the neural levels can be captured by the multifaceted and somewhat ambiguous concept of coarse-to-fine processing, although it is clear that not all temporal changes can be characterized this way. A more comprehensive, albeit unproven, alternative framework for understanding visual temporal dynamics is to view it as a sequential, Bayesian decision-making process. At each step, the visual system infers the likely nature visual scene by jointly evaluating the available processed image information and prior knowledge about the scene, including prior inferences. Whether the processing proceeds in a coarse-to-fine fashion depends largely on whether the underlying computations are hierarchical or not. Characterizing these inferential steps from the computational, perceptual and neural standpoints will be a key part of future work in this emerging field.},
    author = {Hegd\'{e}, Jay},
    citeulike-article-id = {2640777},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.pneurobio.2007.09.001},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17976895},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17976895},
    citeulike-linkout-3 = {http://www.sciencedirect.com/science/article/B6T0R-4PT299H-1/2/a2d614517d19ce894b331c3e0424b476},
    date-added = {2014-01-15 13:22:22},
    doi = {10.1016/j.pneurobio.2007.09.001},
    issn = {0301-0082},
    journal = {Progress in neurobiology},
    keywords = {assofield},
    month = apr,
    number = {4},
    pages = {405--439},
    pmid = {17976895},
    priority = {5},
    title = {Time course of visual perception: coarse-to-fine processing and beyond.},
    url = {http://dx.doi.org/10.1016/j.pneurobio.2007.09.001},
    volume = {84},
    year = {2008}
}

@article{Bacon05,
    abstract = {Human observers are very good at deciding whether briefly flashed novel images contain an animal and previous work has shown that the underlying visual processing can be performed in under 150 ms. Here we used a masking paradigm to determine how information accumulates over time during such high-level categorisation tasks. As the delay between test image and mask is increased, both behavioural accuracy and differential {ERP} amplitude rapidly increase to reach asymptotic levels around 40–60 ms. Such results imply that processing at each stage in the visual system is remarkably rapid, with information accumulating almost continuously following the onset of activation.},
    author = {Bacon-Mac\'{e}, Nad\`{e}ge and Mac\'{e}, Marc J. and Fabre-Thorpe, Mich\`{e}le and Thorpe, Simon J.},
    citeulike-article-id = {6526376},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.visres.2005.01.004},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/15743615},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=15743615},
    date-added = {2014-01-07 09:58:59},
    doi = {10.1016/j.visres.2005.01.004},
    issn = {0042-6989},
    journal = {Vision Research},
    keywords = {assofield, ultra-rapid\_categorization},
    month = may,
    number = {11},
    pages = {1459--1469},
    pmid = {15743615},
    priority = {0},
    title = {The time course of visual processing: Backward masking and natural scene categorisation},
    url = {http://dx.doi.org/10.1016/j.visres.2005.01.004},
    volume = {45},
    year = {2005}
}

@article{Crouzet10,
    abstract = {Previous work has demonstrated that the human visual system can detect animals in complex natural scenes very efficiently and rapidly. In particular, using a saccadic choice task, H. Kirchner and S. J. Thorpe () found that when two images are simultaneously flashed in the left and right visual fields, saccades toward the side with an animal can be initiated in as little as 120–130 ms. Here we show that saccades toward human faces are even faster, with the earliest reliable saccades occurring in just 100–110 ms, and mean reaction times of roughly 140 ms. Intriguingly, it appears that these very fast saccades are not completely under instructional control, because when faces were paired with photographs of vehicles, fast saccades were still biased toward faces even when the subject was targeting vehicles. Finally, we tested whether these very fast saccades might only occur in the simple case where the images are presented left and right of fixation by showing they also occur when the images are presented above and below fixation. Such results impose very serious constraints on the sorts of processing model that can be invoked and demonstrate that face-selective behavioral responses can be generated extremely rapidly.},
    author = {Crouzet, S\'{e}bastien M. and Kirchner, Holle and Thorpe, Simon J.},
    citeulike-article-id = {10301739},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/10.4.16},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/10/4/16.abstract},
    date-added = {2014-01-07 09:41:45},
    day = {28},
    doi = {10.1167/10.4.16},
    journal = {Journal of Vision},
    keywords = {assofield, ultra-rapid\_categorization},
    month = apr,
    number = {4},
    priority = {0},
    title = {Fast saccades toward faces: Face detection in just 100 ms},
    url = {http://www.journalofvision.org/content/10/4/16.abstract},
    volume = {10},
    year = {2010}
}

@article{VanRullen01,
    abstract = {Visual processing is known to be very fast in ultra-rapid categorisation tasks where the subject has to decide whether a briefly flashed image belongs to a target category or not. Human subjects can respond in under 400 ms, and event-related-potential studies have shown that the underlying processing can be done in less than 150 ms. Monkeys trained to perform the same task have proved even faster. However, most of these experiments have only been done with biologically relevant target categories such as animals or food. Here we performed the same study on human subjects, alternating between a task in which the target category was 'animal', and a task in which the target category was 'means of transport'. These natural images of clearly artificial objects contained targets as varied as cars, trucks, trains, boats, aircraft, and hot-air balloons. However, the subjects performed almost identically in both tasks, with reaction times not significantly longer in the 'means of transport' task. These reaction times were much shorter than in any previous study on natural-image processing. We conclude that, at least for these two superordinate categories, the speed of ultra-rapid visual categorisation of natural scenes does not depend on the target category, and that this processing could rely primarily on feed-forward, automatic mechanisms.},
    author = {VanRullen, R. and Thorpe, S. J.},
    citeulike-article-id = {8823331},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11464555},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=11464555},
    date-added = {2014-01-07 09:41:20},
    issn = {0301-0066},
    journal = {Perception},
    keywords = {assofield, ultra-rapid\_categorization},
    number = {6},
    pages = {655--668},
    pmid = {11464555},
    priority = {0},
    title = {Is it a bird? Is it a plane? Ultra-rapid visual categorisation of natural and artifactual objects.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11464555},
    volume = {30},
    year = {2001}
}

@article{Peelen09,
    abstract = {The visual system has an extraordinary capability to extract categorical information from complex natural scenes. For example, subjects are able to rapidly detect the presence of object categories such as animals or vehicles in new scenes that are presented very briefly. This is even true when subjects do not pay attention to the scenes and simultaneously perform an unrelated attentionally demanding task, a stark contrast to the capacity limitations predicted by most theories of visual attention. Here we show a neural basis for rapid natural scene categorization in the visual cortex, using functional magnetic resonance imaging and an object categorization task in which subjects detected the presence of people or cars in briefly presented natural scenes. The multi-voxel pattern of neural activity in the object-selective cortex evoked by the natural scenes contained information about the presence of the target category, even when the scenes were task-irrelevant and presented outside the focus of spatial attention. These findings indicate that the rapid detection of categorical information in natural scenes is mediated by a category-specific biasing mechanism in object-selective cortex that operates in parallel across the visual field, and biases information processing in favour of objects belonging to the target object category.},
    author = {Peelen, Marius V. and Fei-Fei, Li and Kastner, Sabine},
    citeulike-article-id = {4832153},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature08103},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature08103},
    citeulike-linkout-2 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2752739/},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/19506558},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=19506558},
    date-added = {2014-01-06 15:26:42},
    day = {7},
    doi = {10.1038/nature08103},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {assofield, invariant\_object\_recognition, ultra-rapid\_categorization},
    month = jun,
    number = {7251},
    pages = {94--97},
    pmcid = {PMC2752739},
    pmid = {19506558},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Neural mechanisms of rapid natural scene categorization in human visual cortex},
    url = {http://dx.doi.org/10.1038/nature08103},
    volume = {460},
    year = {2009}
}

@article{Bednar12jpp,
    author = {Bednar, James A.},
    citeulike-article-id = {12899231},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jphysparis.2011.12.001},
    date-added = {2014-01-06 14:22:24},
    doi = {10.1016/j.jphysparis.2011.12.001},
    issn = {0928-4257},
    journal = {Journal of Physiology-Paris},
    keywords = {assofield},
    month = sep,
    number = {5-6},
    pages = {194--211},
    priority = {2},
    title = {Building a mechanistic model of the development and function of the primary visual cortex},
    url = {http://dx.doi.org/10.1016/j.jphysparis.2011.12.001},
    volume = {106},
    year = {2012}
}

@article{Li08,
    abstract = {In complex visual scenes, linking related contour elements is important for object recognition. This process, thought to be stimulus driven and hard wired, has substrates in primary visual cortex (V1). Here, however, we find contour integration in V1 to depend strongly on perceptual learning and top-down influences that are specific to contour detection. In naive monkeys, the information about contours embedded in complex backgrounds is absent in V1 neuronal responses and is independent of the locus of spatial attention. Training animals to find embedded contours induces strong contour-related responses specific to the trained retinotopic region. These responses are most robust when animals perform the contour detection task but disappear under anesthesia. Our findings suggest that top-down influences dynamically adapt neural circuits according to specific perceptual tasks. This may serve as a general neuronal mechanism of perceptual learning and reflect top-down mediated changes in cortical states.},
    address = {The Rockefeller University, New York, NY 10065, USA. liwu@bnu.edu.cn},
    author = {Li, Wu and Pi\"{e}ch, Valentin and Gilbert, Charles D.},
    citeulike-article-id = {2702176},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.neuron.2007.12.011},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2409109/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18255036},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18255036},
    citeulike-linkout-4 = {http://www.sciencedirect.com/science/article/B6WSS-4RSB6BB-F/1/c688a1b32ba244b2d43096feaec24cd4},
    date-added = {2014-01-06 13:27:32},
    day = {7},
    doi = {10.1016/j.neuron.2007.12.011},
    issn = {0896-6273},
    journal = {Neuron},
    keywords = {area-v1, assofield, bicv-sparse, grouping},
    month = feb,
    number = {3},
    pages = {442--451},
    pmcid = {PMC2409109},
    pmid = {18255036},
    priority = {5},
    title = {Learning to Link Visual Contours},
    url = {http://dx.doi.org/10.1016/j.neuron.2007.12.011},
    volume = {57},
    year = {2008}
}

@article{McManus11,
    abstract = {The ability to derive meaning from complex sensory input requires the integration of information over space and time, as well as cognitive mechanisms to shape that integration. We studied these processes in the primary visual cortex (V1), where neurons are thought to integrate visual inputs along contours defined by an association field ({AF}). We recorded extracellularly from single cells in macaque V1 to map the {AF}, by using an optimization algorithm to find the contours that maximally activated individual cells. We combined the algorithm with a delayed-match-to-sample task, to test how the optimal contours might be molded by the monkey's expectation for particular cue shapes. We found that V1 neurons were selective for complex shapes, a property previously ascribed to higher cortical areas. Furthermore, the shape selectivity was reprogrammed by perceptual task: Over the whole network, the optimal modes of geometric selectivity shifted between distinct subsets of the {AF}, alternately representing different stimulus features known to predominate in natural scenes. Our results suggest a general model of cortical function, whereby horizontal connections provide a broad domain of potential associations, and top--down inputs dynamically gate these linkages to task switch the function of a network.},
    author = {McManus, J. N. J. and Li, Wu and Gilbert, Charles D.},
    citeulike-article-id = {10163860},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.1105855108},
    citeulike-linkout-1 = {http://www.pnas.org/content/108/24/9739.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/108/24/9739.full.pdf},
    citeulike-linkout-3 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3116391/},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/21571645},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=21571645},
    date-added = {2014-01-06 13:11:08},
    day = {13},
    doi = {10.1073/pnas.1105855108},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {area-v1, association-field, assofield, bicv-sparse, receptive-field},
    month = may,
    number = {24},
    pages = {9739--9746},
    pmcid = {PMC3116391},
    pmid = {21571645},
    priority = {0},
    publisher = {National Academy of Sciences},
    title = {Adaptive shape processing in primary visual cortex},
    url = {http://dx.doi.org/10.1073/pnas.1105855108},
    volume = {108},
    year = {2011}
}

@article{Fischer07,
    abstract = {Abstract--- {M}eanwhile biorthogonal wavelets got a very popu- lar image processing tool, alternative multiresolution transforms have been proposed for solving some of their drawbacks, namely the poor selectivity in orientation and the lack of translation in- variance due to the aliasing between subbands. {T}hese transforms are generally overcomplete and consequently offer huge degrees of freedom in their design. {A}t the same time their optimization get a challenging task. {W}e proposed here a log-{G}abor wavelet transform gathering the excellent mathematical properties of the {G}abor functions with a carefully construction to maintain the properties of the filters and to permit exact reconstruction. {T}wo major improvements are proposed: first the highest frequency bands are covered by narrowly localized oriented filters. {A}nd second, all the frequency bands including the highest and lowest frequencies are uniformly covered so as exact reconstruction is achieved using the same filters in both the direct and the inverse transforms (which means that the transform is self-invertible). {T}he transform is optimized not only mathematically but it also follows as much as possible the knowledge on the receptive field of the simple cells of the {P}rimary {V}isual {C}ortex ({V}1) of primates and on the statistics of natural images. {C}ompared to the state of the art, the log-{G}abor wavelets show excellent behavior in their ability to segregate the image information (e.g. the contrast edges) from incoherent {G}aussian noise by hard thresholding and to code the image features through a reduced set of coefficients with large magnitude. {S}uch characteristics make the transform a promising tool for general image processing tasks.},
    annote = {Special issue on Image Perception.},
    author = {Fischer, Sylvain and Redondo, Rafael and Perrinet, Laurent U. and Crist{\'{o}}bal, Gabriel},
    citeulike-article-id = {12825723},
    citeulike-linkout-0 = {http://dx.doi.org/10.1155/2007/90727},
    date-added = {2013-12-10 14:09:00},
    doi = {10.1155/2007/90727},
    issn = {1687-6180},
    journal = {EURASIP Journal on Advances in Signal Processing},
    keywords = {assofield, bicv-sparse, denoising, filters, high-pass, image, log-gabor, motion-clouds, oriented, perrinet11sfn, sanz12jnp, system, transforms, vacher14, vision, wavelet},
    number = {1},
    pages = {090727--122},
    priority = {0},
    publisher = {Hindawi Publishing Corp.},
    title = {Sparse approximation of images inspired from the functional architecture of the primary visual areas},
    url = {http://dx.doi.org/10.1155/2007/90727},
    volume = {2007},
    year = {2007}
}

@article{Rullen98,
    abstract = {
                The speed with which neurones in the monkey temporal lobe can respond selectively to the presence of a face implies that processing may be possible using only one spike per neurone, a finding that is problematic for conventional rate coding models that need at least two spikes to estimate interspike interval. One way of avoiding this problem uses the fact that integrate-and-fire neurones will tend to fire at different times, with the most strongly activated neurones firing first (Thorpe, 1990, Parallel Processing in Neural Systems). Under such conditions, processing can be performed by using the order in which cells in a particular layer fire as a code. To test this idea, we have explored a range of architectures using {SpikeNET} (Thorpe and Gautrais, 1997, Neural Information Processing Systems, 9), a simulator designed for modelling large populations of integrate-and-fire neurones. One such network used a simple four-layer feed-forward architecture to detect and localise the presence of human faces in natural images. Performance of the model was tested with a large range of grey-scale images of faces and other objects and was found to be remarkably good by comparison with more classic image processing techniques. The most remarkable feature of these results is that they were obtained using a purely feed-forward neural network in which none of the neurones fired more than one spike (thus ruling out conventional rate coding mechanisms). It thus appears that the combination of asynchronous spike propagation and rank order coding may provide an important key to understanding how the nervous system can achieve such a huge amount of processing in so little time.
            },
    author = {Van Rullen, R. and Gautrais, J. and Delorme, A. and Thorpe, S.},
    citeulike-article-id = {12788457},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/9886652},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=9886652},
    date-added = {2013-11-14 13:26:20},
    issn = {0303-2647},
    journal = {Bio Systems},
    keywords = {assofield, invariant\_object\_recognition, ultra-rapid\_categorization},
    number = {1-3},
    pages = {229--239},
    pmid = {9886652},
    priority = {0},
    title = {Face processing using one spike per neurone.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/9886652},
    volume = {48},
    year = {1998}
}

@article{Rousselet02,
    abstract = {Models of visual processing often include an initial parallel stage that is restricted to relatively low-level features, whereas activation of higher-level object descriptions is generally assumed to require attention. Here we report that even high-level object representations can be accessed in parallel: in a rapid animal versus non-animal categorization task, both behavioral and electrophysiological data show that human subjects were as fast at responding to two simultaneously presented natural images as they were to a single one. The implication is that even complex natural images can be processed in parallel without the need for sequential focal attention.},
    author = {Rousselet, Guillaume A. and Fabre-Thorpe, Michele and Thorpe, Simon J.},
    citeulike-article-id = {6492911},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn866},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn866},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/12032544},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=12032544},
    date-added = {2013-11-14 12:54:59},
    doi = {10.1038/nn866},
    issn = {1097-6256},
    journal = {Nat Neurosci},
    keywords = {assofield, categorization, natural\_scene, perrinet11sfn},
    month = jul,
    number = {7},
    pages = {629--630},
    pmid = {12032544},
    priority = {0},
    title = {Parallel processing in high-level categorization of natural images},
    url = {http://dx.doi.org/10.1038/nn866},
    volume = {5},
    year = {2002}
}

@article{Delorme03,
    abstract = {Abstract: Many biological neural network models face the problem of scalability because of the limited computational power of today's computers. Thus, it is difficult to assess the efficiency of these models to solve complex problems such as image processing. Here, we describe how this problem can be tackled using event-driven computation. Only the neurons that emit a discharge are processed and, as long as the average spike discharge rate is low, millions of neurons and billions of connections can be modeled. We describe the underlying computation and implementation of such a mechanism in {SpikeNET}, our neural network simulation package. The type of model one can build is not only biologically compliant, it is also computationally efficient as 400 000 synaptic weights can be propagated per second on a standard desktop computer. In addition, for large networks, we can set very small time steps (less than 0.01 ms) without significantly increasing the computation time. As an example, this method is applied to solve complex cognitive tasks such as face recognition in natural images.},
    author = {Delorme, Arnaud and Thorpe, Simon J.},
    citeulike-article-id = {3988009},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.29},
    date-added = {2013-11-14 09:55:46},
    journal = {Neural Networks},
    keywords = {artificial\_intelligence, assofield},
    pages = {613--627},
    priority = {0},
    title = {Spikenet: an event-driven simulation package for modelling large networks of spiking neurons},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.29},
    volume = {14},
    year = {2003}
}

@article{Dakin98,
    author = {Dakin, S. C. and Hess, R. F.},
    citeulike-article-id = {12723290},
    citeulike-linkout-0 = {http://dx.doi.org/10.1364/josaa.15.001486},
    date-added = {2013-10-16 10:45:11},
    doi = {10.1364/josaa.15.001486},
    issn = {1084-7529},
    journal = {Journal of the Optical Society of America A},
    keywords = {assofield, contour, multi-scale},
    number = {6},
    pages = {1486+},
    priority = {0},
    title = {Spatial-frequency tuning of visual contour integration},
    url = {http://dx.doi.org/10.1364/josaa.15.001486},
    volume = {15},
    year = {1998}
}

@article{Neri11,
    abstract = {
                Visual cortex analyzes images by first extracting relevant details (e.g., edges) via a large array of specialized detectors. The resulting edge map is then relayed to a processing pipeline, the final goal of which is to attribute meaning to the scene. As this process unfolds, does the global interpretation of the image affect how local feature detectors operate? We characterized the local properties of human edge detectors while we manipulated the extent to which the statistical properties of the surrounding image conformed to those encountered in natural vision. Although some aspects of local processing were unaffected by contextual manipulations, we observed significant alterations in the operating characteristics of the detector which were solely attributable to a higher-level semantic interpretation of the scene, unrelated to lower-level aspects of image statistics. Our results suggest that it may be inaccurate to regard early feature detectors as operating outside the domain of higher-level vision; although there is validity in this approach, a full understanding of their properties requires the inclusion of knowledge-based effects specific to the statistical regularities found in the natural environment.
            },
    author = {Neri, Peter},
    citeulike-article-id = {9907038},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fpsyg.2011.00172},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3153857/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/21886631},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=21886631},
    comment = {5. Conclusion
Our primary result is grounded on data, regardless of specific models and/or conceptual frameworks. It consists of the largely unexpected result that higher-level manipulations of image content (i.e., inverting the image upside-down) altered the characteristics of local edge detectors employed by the human observers for feature extraction (see Figure ​Figure15).15). No existing model can account for this effect. Our results demonstrate that even the earliest and simplest stages in human visual processing cannot be fully understood as operating completely outside the domain of higher-level processing; a comprehensive account of low-level vision requires that feature detectors are characterized not only within the controlled parameter range spanned by artificial stimuli (Rust and Movshon, 2005), but also within the operating regime afforded by natural statistics (Felsen and Dan, 2005).
},
    date-added = {2013-10-15 14:27:06},
    doi = {10.3389/fpsyg.2011.00172},
    issn = {1664-1078},
    journal = {Frontiers in Psychology},
    keywords = {assofield, context, edge\_co-occurrence, natural-scenes},
    pmcid = {PMC3153857},
    pmid = {21886631},
    priority = {0},
    title = {Global Properties of Natural Scenes Shape Local Properties of Human Edge Detectors},
    url = {http://dx.doi.org/10.3389/fpsyg.2011.00172},
    volume = {2},
    year = {2011}
}

@article{Michel13,
    abstract = {Here the authors combine computational modeling, voltage-sensitive dye imaging ({VSDI}) in behaving monkeys, and behavioral measurements in humans, to investigate whether the large-scale topography of V1 population responses influences shape judgments. They find the judgments of human observers were systematically distorted as had been predicted based on the {VSDI} responses in monkey V1.},
    author = {Michel, Melchi M. and Chen, Yuzhi and Geisler, Wilson S. and Seidemann, Eyal},
    citeulike-article-id = {12652017},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.3517},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.3517},
    date-added = {2013-09-30 10:12:44},
    day = {15},
    doi = {10.1038/nn.3517},
    issn = {1546-1726},
    journal = {Nature Neuroscience},
    keywords = {area-v1, assofield, population\_coding, shape},
    month = sep,
    number = {10},
    pages = {1477--1483},
    priority = {0},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {An illusion predicted by V1 population activity implicates cortical topography in shape perception},
    url = {http://dx.doi.org/10.1038/nn.3517},
    volume = {16},
    year = {2013}
}

@article{Baldassi13,
    abstract = {
                The anterior inferotemporal cortex ({IT}) is the highest stage along the hierarchy of visual areas that, in primates, processes visual objects. Although several lines of evidence suggest that {IT} primarily represents visual shape information, some recent studies have argued that neuronal ensembles in {IT} code the semantic membership of visual objects (i.e., represent conceptual classes such as animate and inanimate objects). In this study, we investigated to what extent semantic, rather than purely visual information, is represented in {IT} by performing a multivariate analysis of {IT} responses to a set of visual objects. By relying on a variety of machine-learning approaches (including a cutting-edge clustering algorithm that has been recently developed in the domain of statistical physics), we found that, in most instances, {IT} representation of visual objects is accounted for by their similarity at the level of shape or, more surprisingly, low-level visual properties. Only in a few cases we observed {IT} representations of semantic classes that were not explainable by the visual similarity of their members. Overall, these findings reassert the primary function of {IT} as a conveyor of explicit visual shape information, and reveal that low-level visual properties are represented in {IT} to a greater extent than previously appreciated. In addition, our work demonstrates how combining a variety of state-of-the-art multivariate approaches, and carefully estimating the contribution of shape similarity to the representation of object categories, can substantially advance our understanding of neuronal coding of visual objects in cortex.
            },
    author = {Baldassi, Carlo and Alemi-Neissi, Alireza and Pagan, Marino and Dicarlo, James J. and Zecchina, Riccardo and Zoccolan, Davide},
    citeulike-article-id = {12659007},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1003167},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3738466/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/23950700},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=23950700},
    date-added = {2013-09-27 11:19:39},
    day = {8},
    doi = {10.1371/journal.pcbi.1003167},
    issn = {1553-7358},
    journal = {PLoS computational biology},
    keywords = {assofield, categorization, ultra-rapid\_categorization},
    month = aug,
    number = {8},
    pages = {e1003167+},
    pmcid = {PMC3738466},
    pmid = {23950700},
    priority = {0},
    publisher = {Public Library of Science},
    title = {Shape similarity, better than semantic membership, accounts for the structure of visual object representations in a population of monkey inferotemporal neurons.},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1003167},
    volume = {9},
    year = {2013}
}

@incollection{August01,
    abstract = {A Markov process model for contour curvature is introduced via a stochastic differential equation. We analyze the distribution of such curves, and show that its mode is the Euler spiral, a curve minimizing changes in curvature. To probabilistically enhance noisy and low contrast curve images (e.g., edge and line operator responses), we combine this curvature process with the curve indicator random field, which is a prior for ideal curve images. In particular, we provide an expression for a nonlinear, minimum mean square error filter that requires the solution of two elliptic partial differential equations. Initial computations are reported, highlighting how the filter is curvature-selective, even when curvature is absent in the input.},
    author = {August, Jonas and Zucker, StevenW},
    booktitle = {Energy Minimization Methods in Computer Vision and Pattern Recognition},
    citeulike-article-id = {12631971},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44745-8\_33},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/3-540-44745-8\_33},
    date-added = {2013-09-18 09:32:42},
    doi = {10.1007/3-540-44745-8\_33},
    editor = {Figueiredo, M\'{a}rio and Zerubia, Josiane and Jain, AnilK},
    keywords = {assofield, bicv-sparse, curvature, edge\_co-occurrence, markov-chain},
    pages = {497--512},
    priority = {4},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {A Markov Process Using Curvature for Filtering Curve Images},
    url = {http://dx.doi.org/10.1007/3-540-44745-8\_33},
    volume = {2134},
    year = {2001}
}

@article{Pitkow10,
    abstract = {To understand the computations of our visual system, it is important to understand also the natural environment it evolved to interpret. Unfortunately, existing models of the visual environment are either unrealistic or too complex for mathematical description. Here we describe a naturalistic image model and present a mathematical solution for the statistical relationships between the image features and model variables. The world described by this model is composed of independent, opaque, textured objects, which occlude each other. This simple structure allows us to calculate the joint probability distribution of image values sampled at multiple arbitrarily located points, without approximation. This result can be converted into probabilistic relationships between observable image features as well as between the unobservable properties that caused these features, including object boundaries and relative depth. We show that the image model is sufficient to explain a wide range of natural scene properties. Finally, we discuss the implications of this description of natural scenes for the study of vision.},
    author = {Pitkow, Xaq},
    citeulike-article-id = {12631968},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/10.14.42},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/10/14/42.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/10/14/42.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/21196508},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=21196508},
    date-added = {2013-09-18 09:28:27},
    day = {30},
    doi = {10.1167/10.14.42},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, edge\_co-occurrence, occlusion},
    month = dec,
    number = {14},
    pmid = {21196508},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Exact feature probabilities in images with occlusion},
    url = {http://dx.doi.org/10.1167/10.14.42},
    volume = {10},
    year = {2010}
}

@article{Lee03b,
    abstract = {This paper reviews some of the recent neurophysiological studies that explore the variety of visual computations in the early visual cortex in relation to geometric inference, i.e. the inference of contours, surfaces and shapes. It attempts to draw connections between ideas from computational vision and findings from awake primate electrophysiology. In the classical feed-forward, modular view of visual processing, the early visual areas ({LGN}, V1 and V2) are modules that serve to extract local features, while higher extrastriate areas are responsible for shape inference and invariant object recognition. However, recent findings in primate early visual systems reveal that the computations in the early visual cortex are rather complex and dynamic, as well as interactive and plastic, subject to influence from global context, higher order perceptual inference, task requirement and behavioral experience. The evidence argues that the early visual cortex does not merely participate in the first stage of visual processing, but is involved in many levels of visual computation.},
    address = {Center for the Neural Basis of Cognition and Department of Computer Science, Carnegie Mellon University, 4400 Fifth Avenue, Pittsburgh, PA 15213, USA. tai@cnbc.cmu.edu},
    author = {Lee, Tai S.},
    citeulike-article-id = {311440},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jphysparis.2003.09.015},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/14766138},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=14766138},
    date-added = {2013-09-18 09:22:38},
    doi = {10.1016/j.jphysparis.2003.09.015},
    issn = {09284257},
    journal = {Journal of Physiology-Paris},
    keywords = {area-v1, assofield, hierarchical\_model},
    month = mar,
    number = {2-3},
    pages = {121--139},
    pmid = {14766138},
    priority = {2},
    publisher = {Elsevier},
    title = {Computations in the early visual cortex},
    url = {http://dx.doi.org/10.1016/j.jphysparis.2003.09.015},
    volume = {97},
    year = {2003}
}

@inbook{August00,
    abstract = {Can the organization of local edge measurements into curves be directly related to natural image structure? By viewing curve organization as a statistical estimation problem, we suggest that it can. In particular, the classical Gestalt perceptual organization cues of proximity and good continuation---the basis of many current curve organization systems---can be statistically measured in images. As a prior for our estimation approach we introduce the curve indicator random field. In contrast to other techniques that require contour closure or are based on a sparse set of detected edges, the curve indicator random field emphasizes the short-distance, dense nature of organizing curve elements into (possibly) open curves. Its explicit formulation allows the calculation of its properties such as its autocorrelation. On the one hand, the curve indicator random field leads us to introduce the oriented Wiener filter, capturing the blur and noise inherent in the edge measurement process. On the other, it suggests we seek such correlations in natural images. We present the results of some initial edge correlation measurements that not only confirm the presence of Gestalt cues, but also suggest that curvature has a role in curve organization.},
    address = {Boston, MA},
    author = {August, Jonas and Zucker, Steven W.},
    booktitle = {In Perceptual Organization for Artificial Vision Systems},
    chapter = {15},
    citeulike-article-id = {12631916},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-4615-4413-5\_15},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.5066},
    date-added = {2013-09-18 08:32:27},
    doi = {10.1007/978-1-4615-4413-5\_15},
    editor = {Boyer, Kim L. and Sarkar, Sudeep},
    isbn = {978-1-4613-6986-8},
    issn = {0893-3405},
    keywords = {assofield, edge\_co-occurrence, markov\_random\_field},
    pages = {265--288},
    priority = {0},
    publisher = {Springer US},
    title = {The Curve Indicator Random Field: Curve Organization Via Edge Correlation},
    url = {http://dx.doi.org/10.1007/978-1-4615-4413-5\_15},
    volume = {546},
    year = {2000}
}

@article{Serre10,
    abstract = {Neuroscience is beginning to inspire a new generation of seeing machines.},
    address = {New York, NY, USA},
    author = {Serre, Thomas and Poggio, Tomaso},
    citeulike-article-id = {9429637},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1831425},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1831407.1831425},
    date-added = {2013-09-11 15:50:29},
    day = {1},
    doi = {10.1145/1831407.1831425},
    issn = {0001-0782},
    journal = {Communications of the ACM},
    keywords = {assofield, bicv-sparse, feedforward\_hierarchical\_model, hierarchical\_model},
    month = oct,
    number = {10},
    pages = {54--61},
    priority = {4},
    publisher = {ACM},
    title = {A neuromorphic approach to computer vision},
    url = {http://dx.doi.org/10.1145/1831407.1831425},
    volume = {53},
    year = {2010}
}

@article{Freedman01,
    abstract = {The ability to group stimuli into meaningful categories is a fundamental cognitive process. To explore its neural basis, we trained monkeys to categorize computer-generated stimuli as "cats" and "dogs." A morphing system was used to systematically vary stimulus shape and precisely define the category boundary. Neural activity in the lateral prefrontal cortex reflected the category of visual stimuli, even when a monkey was retrained with the stimuli assigned to new categories.},
    author = {Freedman, D. J. and Riesenhuber, M. and Poggio, T. and Miller, E. K.},
    citeulike-article-id = {2449076},
    citeulike-linkout-0 = {http://dx.doi.org/10.1126/science.291.5502.312},
    citeulike-linkout-1 = {http://www.sciencemag.org/content/291/5502/312.abstract},
    citeulike-linkout-2 = {http://www.sciencemag.org/content/291/5502/312.full.pdf},
    citeulike-linkout-3 = {http://www.sciencemag.org/cgi/content/abstract/291/5502/312},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/11209083},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=11209083},
    date-added = {2013-07-09 15:30:07},
    day = {12},
    doi = {10.1126/science.291.5502.312},
    issn = {0036-8075},
    journal = {Science (New York, N.Y.)},
    keywords = {assofield, categorization, ultra-rapid\_categorization},
    month = jan,
    number = {5502},
    pages = {312--316},
    pmid = {11209083},
    priority = {0},
    publisher = {American Association for the Advancement of Science},
    title = {Categorical representation of visual stimuli in the primate prefrontal cortex.},
    url = {http://dx.doi.org/10.1126/science.291.5502.312},
    volume = {291},
    year = {2001}
}

@article{Freeman13,
    abstract = {
                There is no generally accepted account of the function of the second visual cortical area (V2), partly because no simple response properties robustly distinguish V2 neurons from those in primary visual cortex (V1). We constructed synthetic stimuli replicating the higher-order statistical dependencies found in natural texture images and used them to stimulate macaque V1 and V2 neurons. Most V2 cells responded more vigorously to these textures than to control stimuli lacking naturalistic structure; V1 cells did not. Functional magnetic resonance imaging ({fMRI}) measurements in humans revealed differences between V1 and V2 that paralleled the neuronal measurements. The ability of human observers to detect naturalistic structure in different types of texture was well predicted by the strength of neuronal and {fMRI} responses in V2 but not in V1. Together, these results reveal a particular functional role for V2 in the representation of natural image structure.
            },
    author = {Freeman, Jeremy and Ziemba, Corey M. and Heeger, David J. and Simoncelli, Eero P. and Movshon, J. Anthony},
    citeulike-article-id = {12447124},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.3402},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.3402},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/23685719},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=23685719},
    date-added = {2013-07-01 13:52:27},
    day = {19},
    doi = {10.1038/nn.3402},
    issn = {1546-1726},
    journal = {Nat Neurosci},
    keywords = {area-v2, assofield, edges, second-order},
    month = jul,
    number = {7},
    pages = {974--981},
    pmid = {23685719},
    priority = {5},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {A functional and perceptual signature of the second visual area in primates},
    url = {http://dx.doi.org/10.1038/nn.3402},
    volume = {16},
    year = {2013}
}

@article{Brady08,
    abstract = {One of the major lessons of memory research has been that human memory is fallible, imprecise, and subject to interference. Thus, although observers can remember thousands of images, it is widely assumed that these memories lack detail. Contrary to this assumption, here we show that long-term memory is capable of storing a massive number of objects with details from the image. Participants viewed pictures of 2,500 objects over the course of 5.5 h. Afterward, they were shown pairs of images and indicated which of the two they had seen. The previously viewed item could be paired with either an object from a novel category, an object of the same basic-level category, or the same object in a different state or pose. Performance in each of these conditions was remarkably high (92\%, 88\%, and 87\%, respectively), suggesting that participants successfully maintained detailed representations of thousands of images. These results have implications for cognitive models, in which capacity limitations impose a primary computational constraint (e.g., models of object recognition), and pose a challenge to neural models of memory storage and retrieval, which must be able to account for such a large and detailed storage capacity.},
    author = {Brady, Timothy F. and Konkle, Talia and Alvarez, George A. and Oliva, Aude},
    citeulike-article-id = {3332389},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.0803390105},
    citeulike-linkout-1 = {http://www.pnas.org/content/105/38/14325.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/105/38/14325.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/18787113},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=18787113},
    date-added = {2013-06-27 15:33:56},
    day = {23},
    doi = {10.1073/pnas.0803390105},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, invariant\_object\_recognition, memory},
    month = sep,
    number = {38},
    pages = {14325--14329},
    pmid = {18787113},
    priority = {0},
    publisher = {National Academy of Sciences},
    title = {Visual long-term memory has a massive storage capacity for object details},
    url = {http://dx.doi.org/10.1073/pnas.0803390105},
    volume = {105},
    year = {2008}
}

@article{Thorpe96,
    author = {Thorpe, Simon and Fize, Denis and Marlot, Catherine},
    citeulike-article-id = {12421918},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/381520a0},
    date-added = {2013-06-17 14:42:55},
    day = {6},
    doi = {10.1038/381520a0},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {assofield, ultra-rapid\_categorization},
    month = jun,
    number = {6582},
    pages = {520--522},
    priority = {0},
    title = {Speed of processing in the human visual system},
    url = {http://dx.doi.org/10.1038/381520a0},
    volume = {381},
    year = {1996}
}

@article{Perrinet03ieee,
    abstract = {To understand possible strategies of temporal spike coding in the central nervous system, we study functional neuromimetic models of visual processing for static images. We will first present the retinal model which was introduced by Van Rullen and Thorpe [1] and which represents the multi- scale contrast values of the image using an orthonormal wavelet transform. These analog values activate a set of spiking neurons which each fire once to produce an asynchronous wave of spikes. According to this model, the image may be progressively reconstructed from this spike wave thanks to regularities in the statistics of the coefficients determined with natural images. Here, we study mathematically how the quality of information transmission carried by this temporal representation varies over time. In particular, we study how these regularities can be used to optimize information transmission by using a form of temporal cooperation of neurons to code analog values. The original model used wavelet transforms that are close to orthogonal. However, the selectivity of realistic neurons overlap, and we propose an extension of the previous model by adding a spatial cooperation between filters. This model extends the previous scheme for arbitrary ---and possibly non-orthogonal--- representations of features in the images. In particular, we compared the perfor- mance of increasingly over-complete representations in the retina. Results show that this algorithm provides an efficient spike coding strategy for low-level visual processing which may adapt to the complexity of the visual input.},
    author = {Perrinet, L. and Samuelides, M. and Thorpe, S.},
    citeulike-article-id = {12344553},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TNN.2004.833303},
    date-added = {2013-05-15 10:46:35},
    doi = {10.1109/TNN.2004.833303},
    issn = {1045-9227},
    journal = {IEEE Transactions on Neural Networks},
    keywords = {assofield, asynchronous, bicv-sparse, coding, matching-pursuit, natural-scenes, neuronal, over-complete, parallel, parallel-processing, spike, ultra-rapid, vision},
    month = sep,
    note = {Special issue on 'Temporal Coding for Neural Information Processing'},
    number = {5},
    pages = {1164--1175},
    priority = {0},
    title = {Coding Static Natural Images Using Spiking Event Times: Do Neurons Cooperate?},
    url = {http://dx.doi.org/10.1109/TNN.2004.833303},
    volume = {15},
    year = {2004}
}

@article{Melmer13,
    author = {Melmer, Tamara and Amirshahi, Seyed A. and Koch, Michael and Denzler, Joachim and Redies, Christoph},
    citeulike-article-id = {12290589},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fnhum.2013.00106},
    date-added = {2013-04-22 13:31:38},
    doi = {10.3389/fnhum.2013.00106},
    issn = {1662-5161},
    journal = {Frontiers in Human Neuroscience},
    keywords = {art, assofield, natural\_images\_statistics},
    priority = {0},
    title = {From regular text to artistic writing and artworks: Fourier statistics of images with low and high aesthetic appeal},
    url = {http://dx.doi.org/10.3389/fnhum.2013.00106},
    volume = {7},
    year = {2013}
}

@article{Moreno03,
    author = {Moreno, Pedro J. and Ho, Purdy and Vasconcelos, Nuno},
    citeulike-article-id = {12216277},
    citeulike-linkout-0 = {http://math.stackexchange.com/questions/31515/kullback-leibler-divergence-based-kernel},
    date-added = {2013-03-27 14:01:56},
    journal = {Advances in neural information processing systems},
    keywords = {assofield},
    pages = {1385--1393},
    priority = {2},
    title = {A {Kullback-Leibler} divergence based kernel for {SVM} classification in multimedia applications},
    url = {http://math.stackexchange.com/questions/31515/kullback-leibler-divergence-based-kernel},
    volume = {16},
    year = {2003}
}

@article{Fleming11,
    abstract = {One of the main functions of vision is to estimate the {3D} shape of objects in our environment. Many different visual cues, such as stereopsis, motion parallax, and shading, are thought to be involved. One important cue that remains poorly understood comes from surface texture markings. When a textured surface is slanted in {3D} relative to the observer, the surface patterns appear compressed in the retinal image, providing potentially important information about {3D} shape. What is not known, however, is how the brain actually measures this information from the retinal image. Here, we explain how the key information could be extracted by populations of cells tuned to different orientations and spatial frequencies, like those found in the primary visual cortex. To test this theory, we created stimuli that selectively stimulate such cell populations, by '' smearing'' (filtering) images of {2D} random noise into specific oriented patterns. We find that the resulting patterns appear vividly {3D}, and that increasing the strength of the orientation signals progressively increases the sense of {3D} shape, even though the filtering we apply is physically inconsistent with what would occur with a real object. This finding suggests we have isolated key mechanisms used by the brain to estimate shape from texture. Crucially, we also find that adapting the visual system's orientation detectors to orthogonal patterns causes unoriented random noise to look like a specific {3D} shape. Together these findings demonstrate a crucial role of orientation detectors in the perception of {3D} shape.},
    author = {Fleming, Roland W. and Holtmann-Rice, Daniel and B\"{u}lthoff, Heinrich H.},
    citeulike-article-id = {10216190},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.1114619109},
    citeulike-linkout-1 = {http://www.pnas.org/content/108/51/20438.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/108/51/20438.full.pdf},
    citeulike-linkout-3 = {http://www.pnas.org/cgi/content/abstract/108/51/20438},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/22147916},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=22147916},
    date-added = {2013-03-19 21:30:57},
    day = {20},
    doi = {10.1073/pnas.1114619109},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, orientation, pattern, shape},
    month = dec,
    number = {51},
    pages = {20438--20443},
    pmid = {22147916},
    priority = {5},
    publisher = {National Academy of Sciences},
    title = {Estimation of {3D} shape from image orientations},
    url = {http://dx.doi.org/10.1073/pnas.1114619109},
    volume = {108},
    year = {2011}
}

@article{Srinivasa13,
    abstract = {This study describes a spiking model that self-organizes for stable formation and maintenance of orientation and ocular dominance maps in the visual cortex (V1). This self-organization process simulates three development phases: an early experience-independent phase, a late experience-independent phase and a subsequent refinement phase during which experience acts to shape the map properties. The ocular dominance maps that emerge accommodate the two sets of monocular inputs that arise from the lateral geniculate nucleus ({LGN}) to layer 4 of V1. The orientation selectivity maps that emerge feature well-developed iso-orientation domains and fractures. During the last two phases of development the orientation preferences at some locations appear to rotate continuously through \$\\pm\$180\$\\,^{\\circ}\$ along circular paths and referred to as pinwheel-like patterns but without any corresponding point discontinuities in the orientation gradient maps. The formation of these functional maps is driven by balanced excitatory and inhibitory currents that are established via synaptic plasticity based on spike timing for both excitatory and inhibitory synapses. The stability and maintenance of the formed maps with continuous synaptic plasticity is enabled by homeostasis caused by inhibitory plasticity. However, a prolonged exposure to repeated stimuli does alter the formed maps over time due to plasticity. The results from this study suggest that continuous synaptic plasticity in both excitatory neurons and interneurons could play a critical role in the formation, stability, and maintenance of functional maps in the cortex.},
    author = {Srinivasa, Narayan and Jiang, Qin},
    citeulike-article-id = {12104054},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fncom.2013.00010},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3583036/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/23450808},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=23450808},
    date-added = {2013-03-06 16:05:09},
    doi = {10.3389/fncom.2013.00010},
    issn = {1662-5188},
    journal = {Frontiers in computational neuroscience},
    keywords = {assofield, orientation-selectivity, self\_organization, spikes},
    pmcid = {PMC3583036},
    pmid = {23450808},
    priority = {4},
    title = {Stable learning of functional maps in self-organizing spiking neural networks with continuous synaptic plasticity.},
    url = {http://dx.doi.org/10.3389/fncom.2013.00010},
    volume = {7},
    year = {2013}
}

@article{Sanguinetti10,
    abstract = {In this paper, we propose to model the edge information contained in natural scenes as points in the {3D} space of positions and orientations. This space is equipped with a strong geometrical structure and it is identified as the rototranslation group. In this space, we compute a histogram of co-occurrence of edges from a database of natural images and show that it can be interpreted as a probability density function, expressed by the fundamental solution of a suitable {Fokker--Planck} equation defined in the {3D} structured space. Both estimated statistics and model predictions are reconsidered and compared with the partial gestalt association fields proposed by D. J. Field, A. Hayes, and R. F. Hess (1993). Finally, parametric identification allows to estimate the variance of the co-occurrence random process in natural images.},
    author = {Sanguinetti, Gonzalo and Citti, Giovanna and Sarti, Alessandro},
    citeulike-article-id = {9810615},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/10.14.37},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/10/14/37.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/10/14/37.full.pdf},
    citeulike-linkout-3 = {http://www.journalofvision.org/cgi/content/abstract/10/14/37},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/21196513},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=21196513},
    date-added = {2013-02-08 16:25:57},
    day = {29},
    doi = {10.1167/10.14.37},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield},
    month = dec,
    number = {14},
    pmid = {21196513},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {A model of natural image edge co-occurrence in the rototranslation group},
    url = {http://dx.doi.org/10.1167/10.14.37},
    volume = {10},
    year = {2010}
}

@article{Chossat09,
    abstract = {We propose to use bifurcation theory and pattern formation as theoretical probes for various hypotheses about the neural organization of the brain. This allows us to make predictions about the kinds of patterns that should be observed in the activity of real brains through, e.g., optical imaging, and opens the door to the design of experiments to test these hypotheses. We study the specific problem of visual edges and textures perception and suggest that these features may be represented at the population level in the visual cortex as a specific second-order tensor, the structure tensor, perhaps within a hypercolumn. We then extend the classical ring model to this case and show that its natural framework is the {non-Euclidean} hyperbolic geometry. This brings in the beautiful structure of its group of isometries and certain of its subgroups which have a direct interpretation in terms of the organization of the neural populations that are assumed to encode the structure tensor. By studying the bifurcations of the solutions of the structure tensor equations, the analog of the classical Wilson and Cowan equations, under the assumption of invariance with respect to the action of these subgroups, we predict the appearance of characteristic patterns. These patterns can be described by what we call hyperbolic or H-planforms that are reminiscent of Euclidean planar waves and of the planforms that were used in previous work to account for some visual hallucinations. If these patterns could be observed through brain imaging techniques they would reveal the built-in or acquired invariance of the neural organization to the action of the corresponding subgroups. Our visual perception of the world is remarkably stable despite the fact that we move our gaze and body. This must be the effect of the neuronal organization of the visual areas of our brains that succeed in maintaining in our consciouness a representation that seems to be protected from brutal variations. We propose a theory to account for an invariance that pertains to such image features as edges and textures. It is based on the simple assumption that the spatial variations of the image intensity, its derivatives, are extracted and represented in some visual brain areas by populations of neurons that excite and inhibit each other according to the values of these derivatives. Geometric transformations of the retinal image, caused say by eye movements, affect these derivatives. Assuming that their representations are invariant to these transformations, we predict the appearance of specific patterns of activity which we call hyperbolic planforms. It is surprising that the geometry that emerges from our investigations is not the usual Euclidean geometry but the much less familiar hyperbolic, {non-Euclidean}, geometry. We also propose some preliminary ideas for putting our theory to the test by actual measurements of brain activity.},
    author = {Chossat, Pascal and Faugeras, Olivier},
    citeulike-article-id = {12007497},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1000625},
    date-added = {2013-02-08 16:25:37},
    day = {24},
    doi = {10.1371/journal.pcbi.1000625},
    journal = {PLoS Comput Biol},
    keywords = {assofield, texture},
    month = dec,
    number = {12},
    pages = {e1000625+},
    priority = {5},
    publisher = {Public Library of Science},
    title = {Hyperbolic Planforms in Relation to Visual Edges and Textures Perception},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1000625},
    volume = {5},
    year = {2009}
}

@article{Gerhard13,
    abstract = {A key hypothesis in sensory system neuroscience is that sensory representations are adapted to the statistical regularities in sensory signals and thereby incorporate knowledge about the outside world. Supporting this hypothesis, several probabilistic models of local natural image regularities have been proposed that reproduce neural response properties. Although many such physiological links have been made, these models have not been linked directly to visual sensitivity. Previous psychophysical studies of sensitivity to natural image regularities focus on global perception of large images, but much less is known about sensitivity to local natural image regularities. We present a new paradigm for controlled psychophysical studies of local natural image regularities and compare how well such models capture perceptually relevant image content. To produce stimuli with precise statistics, we start with a set of patches cut from natural images and alter their content to generate a matched set whose joint statistics are equally likely under a probabilistic natural image model. The task is forced choice to discriminate natural patches from model patches. The results show that human observers can learn to discriminate the higher-order regularities in natural images from those of model samples after very few exposures and that no current model is perfect for patches as small as 5 by 5 pixels or larger. Discrimination performance was accurately predicted by model likelihood, an information theoretic measure of model efficacy, indicating that the visual system possesses a surprisingly detailed knowledge of natural image higher-order correlations, much more so than current image models. We also perform three cue identification experiments to interpret how model features correspond to perceptually relevant image features. Several aspects of primate visual physiology have been identified as adaptations to local regularities of natural images. However, much less work has measured visual sensitivity to local natural image regularities. Most previous work focuses on global perception of large images and shows that observers are more sensitive to visual information when image properties resemble those of natural images. In this work we measure human sensitivity to local natural image regularities using stimuli generated by patch-based probabilistic natural image models that have been related to primate visual physiology. We find that human observers can learn to discriminate the statistical regularities of natural image patches from those represented by current natural image models after very few exposures and that discriminability depends on the degree of regularities captured by the model. The quick learning we observed suggests that the human visual system is biased for processing natural images, even at very fine spatial scales, and that it has a surprisingly large knowledge of the regularities in natural images, at least in comparison to the state-of-the-art statistical models of natural images.},
    author = {Gerhard, Holly E. and Wichmann, Felix A. and Bethge, Matthias},
    citeulike-article-id = {11966485},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1002873},
    date-added = {2013-02-01 10:49:43},
    day = {24},
    doi = {10.1371/journal.pcbi.1002873},
    journal = {PLoS Comput Biol},
    keywords = {assofield, discrimination, natural-scenes, natural\_images\_statistics},
    month = jan,
    number = {1},
    pages = {e1002873+},
    priority = {0},
    publisher = {Public Library of Science},
    title = {How Sensitive Is the Human Visual System to the Local Statistics of Natural Images?},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1002873},
    volume = {9},
    year = {2013}
}

@article{Sincich01,
    abstract = {One important aspect of the functional architecture of primary visual cortex is the circuitry that accounts for the receptive field properties of neurons. The anatomy that underlies retinotopy and ocular dominance is well known, but no anatomical structure related to orientation selectivity has been found in primates. We examined whether the arrangement of local axon systems projecting within the cortical layers might be correlated with orientation preference in New World monkeys. We found that axons in layer 3 spread out from the site of a tracer injection in an anisotropic manner and that this elongated distribution is aligned with the preferred orientation recorded at each site. Moreover, within a few degrees of the foveal representation, the majority of the axon terminals fall within or just outside of the limits of the cortical mapping of the classical receptive field. Thus local axons produce a field of monosynaptic excitation that aligns with orientation axes and reaches neurons that have receptive fields which are adjacent in visual space.},
    author = {Sincich, Lawrence C. and Blasdel, Gary G.},
    citeulike-article-id = {11973770},
    citeulike-linkout-0 = {http://www.jneurosci.org/cgi/content/abstract/21/12/4416},
    date-added = {2013-01-30 16:46:57},
    journal = {The Journal of Neuroscience},
    keywords = {assofield},
    pages = {4416--4426},
    priority = {2},
    title = {Oriented Axon Projections in Primary Visual Cortex of the Monkey},
    url = {http://www.jneurosci.org/cgi/content/abstract/21/12/4416},
    volume = {21},
    year = {2001}
}

@article{Ito04,
    abstract = {Angles and junctions embedded within contours are important features to represent the shape of objects. To study the neuronal basis to extract these features, we conducted extracellular recordings while two macaque monkeys performed a fixation task. Angle stimuli were the combination of two straight half-lines larger than the size of the classical receptive fields ({CRFs}). Each line was drawn from the center to outside the {CRFs} in 1 of 12 directions, so that the stimuli passed through the {CRFs} and formed angles at the center of the {CRFs}. Of 114 neurons recorded from the superficial layer of area V2, 91 neurons showed selective responses to these angle stimuli. Of these, 41 neurons (36.0\%) showed selective responses to wide angles between 60\$\\,^{\\circ}\$ and 150\$\\,^{\\circ}\$ that were distinct from responses to straight lines or sharp angles (30\$\\,^{\\circ}\$). Responses were highly selective to a particular angle in approximately one-fourth of neurons. When we tested the selectivity of the same neurons to individual half-lines, the preferred direction was more or less consistent with one or two components of the optimal angle stimuli. These results suggest that the selectivity of the neurons depends on both the combination of two components and the responses to individual components. Angle-selective V2 neurons are unlikely to be specific angle detectors, because the magnitude of their responses to the optimal angle was indistinguishable from that to the optimal half-lines. We suggest that the extraction of information of angles embedded within contour stimuli may start in area V2.},
    author = {Ito, Minami and Komatsu, Hidehiko},
    citeulike-article-id = {451606},
    citeulike-linkout-0 = {http://dx.doi.org/10.1523/jneurosci.4364},
    citeulike-linkout-1 = {http://www.jneurosci.org/content/24/13/3313.abstract},
    citeulike-linkout-2 = {http://www.jneurosci.org/content/24/13/3313.full.pdf},
    citeulike-linkout-3 = {http://www.jneurosci.org/cgi/content/abstract/24/13/3313},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/15056711},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=15056711},
    date-added = {2013-01-18 09:47:22},
    day = {31},
    doi = {10.1523/jneurosci.4364},
    issn = {1529-2401},
    journal = {The Journal of Neuroscience},
    keywords = {area-v2, assofield, chevron},
    month = mar,
    number = {13},
    pages = {3313--3324},
    pmid = {15056711},
    priority = {2},
    publisher = {Society for Neuroscience},
    title = {Representation of Angles Embedded within Contour Stimuli in Area V2 of Macaque Monkeys},
    url = {http://dx.doi.org/10.1523/jneurosci.4364},
    volume = {24},
    year = {2004}
}

@article{Boynton04,
    abstract = {Surprisingly little is known about the role of V2 in visual processing. A recent study found that the responses of V2 neurons to pairs of angled lines could be predicted from their responses to the individual line components. A simple analysis shows how these neurons may simply sum the responses from one or more orientation selective V1 neurons.},
    address = {Systems Neurobiology Laboratory, Vision Research Laboratory, The Salk Institute for Biological Studies, La Jolla, California 92037, USA. boynton@salk.edu},
    author = {Boynton, Geoffrey M. and Hegd\'{e}, Jay},
    citeulike-article-id = {1197703},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cub.2004.06.044},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/15242635},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=15242635},
    date-added = {2013-01-18 09:44:27},
    day = {13},
    doi = {10.1016/j.cub.2004.06.044},
    issn = {09609822},
    journal = {Current Biology},
    keywords = {area-v2, assofield, chevron},
    month = jul,
    number = {13},
    pages = {R523--R524},
    pmid = {15242635},
    priority = {2},
    title = {Visual Cortex: The Continuing Puzzle of Area V2},
    url = {http://dx.doi.org/10.1016/j.cub.2004.06.044},
    volume = {14},
    year = {2004}
}

@article{Anzai07,
    abstract = {Contours and textures are important attributes of object surfaces, and are often described by combinations of local orientations in visual images. To elucidate the neural mechanisms underlying contour and texture processing, we examined receptive field ({RF}) structures of neurons in visual area V2 of the macaque monkey for encoding combinations of orientations. By measuring orientation tuning at several locations within the classical {RF}, we found that a majority (70\%) of V2 neurons have similar orientation tuning throughout the {RF}. However, many others have {RFs} containing subregions tuned to different orientations, most commonly about 90 degrees apart. By measuring interactions between two positions within the {RF}, we found that approximately one-third of neurons show inhibitory interactions that make them selective for combinations of orientations. These results indicate that V2 neurons could play an important role in analyzing contours and textures and could provide useful cues for surface segmentation.},
    author = {Anzai, Akiyuki and Peng, Xinmiao and Van Essen, David C.},
    citeulike-article-id = {1695864},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn1975},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn1975},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/17873872},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=17873872},
    date-added = {2013-01-18 09:43:07},
    doi = {10.1038/nn1975},
    issn = {1097-6256},
    journal = {Nature neuroscience},
    keywords = {area-v2, assofield, chevron},
    month = oct,
    number = {10},
    pages = {1313--1321},
    pmid = {17873872},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Neurons in monkey visual area V2 encode combinations of orientations.},
    url = {http://dx.doi.org/10.1038/nn1975},
    volume = {10},
    year = {2007}
}

@article{Hubel65,
    author = {Hubel, D. H. and Wiesel, T. N.},
    citeulike-article-id = {3733221},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/14283058},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/14283058},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=14283058},
    date-added = {2013-01-18 09:24:28},
    day = {01},
    issn = {0022-3077},
    journal = {Journal of Neurophysiology},
    keywords = {area-v2, assofield, chevron},
    month = mar,
    number = {2},
    pages = {229--289},
    pmid = {14283058},
    priority = {2},
    publisher = {American Physiological Society},
    title = {Receptive fields and functional architecture in two nonstriate visual areas (18 and 19) of the cat},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/14283058},
    volume = {28},
    year = {1965}
}

@inproceedings{Perrinet08spie,
    abstract = {If modern computers are sometimes superior to cognition in some specialized tasks such as playing chess or browsing a large database, they can't beat the efficiency of biological vision for such simple tasks as recognizing a relative or following an object in a complex background. We present in this paper our attempt at outlining the dynamical, parallel and event-based representation for vision in the architecture of the central nervous system. We will illustrate this by showing that in a signal matching framework, a {L/LN} (linear/non-linear) cascade may efficiently transform a sensory signal into a neural spiking signal and we apply this framework to a model retina. However, this code gets redundant when using an over-complete basis as is necessary for modeling the primary visual cortex: we therefore optimize the efficiency cost by increasing the sparseness of the code. This is implemented by propagating and canceling redundant information using lateral interactions. We compare the efficiency of this representation in terms of compression as the reconstruction quality as a function of the coding length. This will correspond to a modification of the Matching Pursuit algorithm where the {ArgMax} function is optimized for competition, or Competition Optimized Matching Pursuit ({COMP}). We will particularly focus on bridging neuroscience and image processing and on the advantages of such an interdisciplinary approach.},
    author = {Perrinet, Laurent U.},
    booktitle = {Optical and Digital Image Processing Conference 7000 - Proceedings of SPIE Volume 7000, 7 - 11 April 2008},
    citeulike-article-id = {11870799},
    date-added = {2013-01-09 09:14:33},
    editor = {Peter Schelkens, Gabriel C.},
    keywords = {assofield, bicv-sparse, coding, comp, competition, computation, correlation-based, decorrelation, inhibition, matching, matching-pursuit, neural, optimized, population, pursuit, sparse, spike, spike-event},
    number = {1},
    priority = {0},
    publisher = {SPIE},
    title = {Adaptive Sparse Spike Coding : applications of Neuroscience to the compression of natural images},
    volume = {7000},
    year = {2008}
}

@article{Perrinet02sparse,
    author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
    citeulike-article-id = {11870797},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.neucom.2004.01.010},
    comment = {Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann},
    date-added = {2013-01-09 09:14:33},
    doi = {10.1016/j.neucom.2004.01.010},
    issn = {0925-2312},
    journal = {Neurocomputing},
    keywords = {assofield, matching, pursuit},
    month = mar,
    note = {Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann},
    pages = {125--134},
    priority = {0},
    title = {Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit},
    url = {http://dx.doi.org/10.1016/j.neucom.2004.01.010},
    volume = {57},
    year = {2004}
}

@article{Mallat93,
    author = {Mallat, St{\'{e}}phane and Zhang, Zhifeng},
    citeulike-article-id = {11870795},
    date-added = {2013-01-09 09:14:33},
    journal = {I{EEE} {T}ransactions on {S}ignal {P}rocessing},
    keywords = {assofield, bicv-sparse, matching, matching-pursuit, pursuit},
    number = {12},
    pages = {3397--3414},
    priority = {2},
    title = {Matching {P}ursuit with time-frequency dictionaries},
    volume = {41},
    year = {1993}
}

@article{Olshausen97,
    abstract = {The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and bandpass, comparable to the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images (Olshausen and Field, 1996a). Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete---i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output fun...},
    author = {Olshausen, Bruno A. and Field, David J.},
    citeulike-article-id = {9026860},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0042-6989(97)00169-7},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.712},
    date-added = {2013-01-08 13:46:35},
    doi = {10.1016/S0042-6989(97)00169-7},
    issn = {0042-6989},
    journal = {Vision Research},
    keywords = {area-v1, assofield, bicv-sparse, sparse\_hebbian\_learning},
    month = dec,
    number = {23},
    pages = {3311--3325},
    priority = {0},
    title = {Sparse coding with an overcomplete basis set: A strategy employed by {V1}?},
    url = {http://dx.doi.org/10.1016/S0042-6989(97)00169-7},
    volume = {37},
    year = {1997}
}

@article{Shriki12,
    abstract = {Understanding how populations of neurons encode sensory information is a major goal of systems neuroscience. Attempts to answer this question have focused on responses measured over several hundred milliseconds, a duration much longer than that frequently used by animals to make decisions about the environment. How reliably sensory information is encoded on briefer time scales, and how best to extract this information, is unknown. Although it has been proposed that neuronal response latency provides a major cue for fast decisions in the visual system, this hypothesis has not been tested systematically and in a quantitative manner. Here we use a simple 'race to threshold' readout mechanism to quantify the information content of spike time latency of primary visual (V1) cortical cells to stimulus orientation. We find that many V1 cells show pronounced tuning of their spike latency to stimulus orientation and that almost as much information can be extracted from spike latencies as from firing rates measured over much longer durations. To extract this information, stimulus onset must be estimated accurately. We show that the responses of cells with weak tuning of spike latency can provide a reliable onset detector. We find that spike latency information can be pooled from a large neuronal population, provided that the decision threshold is scaled linearly with the population size, yielding a processing time of the order of a few tens of milliseconds. Our results provide a novel mechanism for extracting information from neuronal populations over the very brief time scales in which behavioral judgments must sometimes be made.},
    author = {Shriki, Oren and Kohn, Adam and Shamir, Maoz},
    citeulike-article-id = {10797157},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1002536},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3375217/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22719237},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22719237},
    date-added = {2012-06-17 14:09:31},
    day = {14},
    doi = {10.1371/journal.pcbi.1002536},
    issn = {1553-7358},
    journal = {PLoS Comput Biol},
    keywords = {area-v1, assofield, orientation-selectivity, perrinet11sfn, ultra\_fast},
    month = jun,
    number = {6},
    pages = {e1002536+},
    pmcid = {PMC3375217},
    pmid = {22719237},
    priority = {5},
    publisher = {Public Library of Science},
    title = {Fast coding of orientation in primary visual cortex},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1002536},
    volume = {8},
    year = {2012}
}

@article{Pedregosa11,
    author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
    citeulike-article-id = {10710091},
    date-added = {2012-05-28 13:10:24},
    journal = {Journal of Machine Learning Research},
    keywords = {assofield, perrinet11sfn},
    pages = {2825--2830},
    priority = {2},
    title = {Scikit-learn: Machine Learning in {Python}},
    volume = {12},
    year = {2011}
}

@article{Ernst12,
    abstract = {For processing and segmenting visual scenes, the brain is required to combine a multitude of features and sensory channels. It is neither known if these complex tasks involve optimal integration of information, nor according to which objectives computations might be performed. Here, we investigate if optimal inference can explain contour integration in human subjects. We performed experiments where observers detected contours of curvilinearly aligned edge configurations embedded into randomly oriented distractors. The key feature of our framework is to use a generative process for creating the contours, for which it is possible to derive a class of ideal detection models. This allowed us to compare human detection for contours with different statistical properties to the corresponding ideal detection models for the same stimuli. We then subjected the detection models to realistic constraints and required them to reproduce human decisions for every stimulus as well as possible. By independently varying the four model parameters, we identify a single detection model which quantitatively captures all correlations of human decision behaviour for more than 2000 stimuli from 42 contour ensembles with greatly varying statistical properties. This model reveals specific interactions between edges closely matching independent findings from physiology and psychophysics. These interactions imply a statistics of contours for which edge stimuli are indeed optimally integrated by the visual system, with the objective of inferring the presence of contours in cluttered scenes. The recurrent algorithm of our model makes testable predictions about the temporal dynamics of neuronal populations engaged in contour integration, and it suggests a strong directionality of the underlying functional anatomy. Since Helmholtz put forward his concept that the brain performs inference on its sensory input for building an internal representation of the outside world, it is a puzzle for neuroscientific research whether visual perception can indeed be understood from first principles. An important part of vision is the integration of colinearly aligned edge elements into contours, which is required for the detection of object boundaries. We show that this visual function can fully be explained in a probabilistic model with a well--defined statistical objective. For this purpose, we developed a novel method to adapt models to correlations in human behaviour, and applied this technique to tightly link psychophysical experiments and numerical simulations of contour integration. The results not only demonstrate that complex neuronal computations can be elegantly described in terms of constrained probabilistic inference, but also reveal yet unknown neural mechanisms underlying early visual information processing.},
    author = {Ernst, Udo A. and Mandon, Sunita and Schinkel-Bielefeld, Nadja and Neitzel, Simon D. and Kreiter, Andreas K. and Pawelzik, Klaus R.},
    citeulike-article-id = {10705817},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1002520},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3360074/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22654653},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22654653},
    date-added = {2012-05-26 10:56:40},
    day = {24},
    doi = {10.1371/journal.pcbi.1002520},
    issn = {1553-7358},
    journal = {PLoS computational biology},
    keywords = {assofield, perrinet11sfn},
    month = may,
    number = {5},
    pages = {e1002520+},
    pmcid = {PMC3360074},
    pmid = {22654653},
    priority = {5},
    publisher = {Public Library of Science},
    title = {Optimality of human contour integration},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1002520},
    volume = {8},
    year = {2012}
}

@article{Crouzet11b,
    abstract = {Research progress in machine vision has been very significant in recent years. Robust face detection and identification algorithms are already readily available to consumers, and modern computer vision algorithms for generic object recognition are now coping with the richness and complexity of natural visual scenes. Unlike early vision models of object recognition that emphasized the role of figure-ground segmentation and spatial information between parts, recent successful approaches are based on the computation of loose collections of image features without prior segmentation or any explicit encoding of spatial relations. While these models remain simplistic models of visual processing, they suggest that, in principle, bottom-up activation of a loose collection of image features could support the rapid recognition of natural object categories and provide an initial coarse visual representation before more complex visual routines and attentional mechanisms take place. Focusing on biologically plausible computational models of (bottom-up) pre-attentive visual recognition, we review some of the key visual features that have been described in the literature. We discuss the consistency of these feature-based representations with classical theories from visual psychology and test their ability to account for human performance on a rapid object categorization task.},
    author = {Crouzet, S\'{e}bastien M. and Serre, Thomas},
    citeulike-article-id = {10403201},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fpsyg.2011.00326},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3216029/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22110461},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22110461},
    date-added = {2012-05-21 22:11:31},
    doi = {10.3389/fpsyg.2011.00326},
    issn = {1664-1078},
    journal = {Frontiers in Psychology},
    keywords = {assofield, bicv-sparse, perrinet11sfn},
    pages = {326+},
    pmcid = {PMC3216029},
    pmid = {22110461},
    priority = {2},
    title = {What are the visual features underlying rapid object recognition?},
    url = {http://dx.doi.org/10.3389/fpsyg.2011.00326},
    volume = {2},
    year = {2011}
}

@article{Serre07,
    abstract = {Primates are remarkably good at recognizing objects. The level of performance of their visual system and its robustness to image degradations still surpasses the best computer vision systems despite decades of engineering effort. In particular, the high accuracy of primates in ultra rapid object categorization and rapid serial visual presentation tasks is remarkable. Given the number of processing stages involved and typical neural latencies, such rapid visual processing is likely to be mostly feedforward. Here we show that a specific implementation of a class of feedforward theories of object recognition (that extend the Hubel and Wiesel simple-to-complex cell hierarchy and account for many anatomical and physiological constraints) can predict the level and the pattern of performance achieved by humans on a rapid masked animal vs. non-animal categorization task.},
    author = {Serre, Thomas and Oliva, Aude and Poggio, Tomaso},
    citeulike-article-id = {1270316},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.0700622104},
    citeulike-linkout-1 = {http://www.pnas.org/content/104/15/6424.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/104/15/6424.full.pdf},
    citeulike-linkout-3 = {http://www.pnas.org/cgi/content/abstract/104/15/6424},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/17404214},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=17404214},
    date-added = {2012-05-21 22:08:02},
    day = {10},
    doi = {10.1073/pnas.0700622104},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, bicv-sparse, perrinet11sfn},
    month = apr,
    number = {15},
    pages = {6424--6429},
    pmid = {17404214},
    priority = {2},
    publisher = {National Academy of Sciences},
    title = {A feedforward architecture accounts for rapid categorization},
    url = {http://dx.doi.org/10.1073/pnas.0700622104},
    volume = {104},
    year = {2007}
}

@article{Rousselet03,
    abstract = {Object categorization can be extremely fast. But among all objects, human faces might hold a special status that could depend on a specialized module. Visual processing could thus be faster for faces than for any other kind of object. Moreover, because face processing might rely on facial configuration, it could be more disrupted by stimulus inversion. Here we report two experiments that compared the rapid categorization of human faces and animals or animal faces in the context of upright and inverted natural scenes. In Experiment 1, the natural scenes contained human faces and animals in a full range of scales from close-up to far views. In Experiment 2, targets were restricted to close-ups of human faces and animal faces. Both experiments revealed the remarkable object processing efficiency of our visual system and further showed (1) virtually no advantage for faces over animals; (2) very little performance impairment with inversion; and (3) greater sensitivity of faces to inversion. These results are interpreted within the framework of a unique system for object processing in the ventral pathway. In this system, evidence would accumulate very quickly and efficiently to categorize visual objects, without involving a face module or a mental rotation mechanism. It is further suggested that rapid object categorization in natural scenes might not rely on high-level features but rather on features of intermediate complexity.},
    author = {Rousselet, Guillaume A. and Mac\'{e}, Marc J. M. and Fabre-Thorpe, Mich\`{e}le},
    citeulike-article-id = {10690789},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/3.6.5},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/3/6/5.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/3/6/5.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/12901715},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=12901715},
    date-added = {2012-05-21 15:15:53},
    day = {31},
    doi = {10.1167/3.6.5},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, perrinet11sfn},
    month = jul,
    number = {6},
    pmid = {12901715},
    priority = {2},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {Is it an animal? Is it a human face? Fast processing in upright and inverted natural scenes},
    url = {http://dx.doi.org/10.1167/3.6.5},
    volume = {3},
    year = {2003}
}

@article{Gaspar09,
    abstract = {Amplitude spectra might provide information for natural scene classification. Amplitude does play a role in animal detection because accuracy suffers when amplitude is normalized. However, this effect could be due to an interaction between phase and amplitude, rather than to a loss of amplitude-only information. We used an amplitude-swapping paradigm to establish that animal detection is partly based on an interaction between phase and amplitude. A difference in false alarms for two subsets of our distractor stimuli suggests that the classification of scene environment (man-made versus natural) may also be based on an interaction between phase and amplitude. Examples of interaction between amplitude and phase are discussed.},
    author = {Gaspar, Carl M. and Rousselet, Guillaume A.},
    citeulike-article-id = {5924028},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.visres.2009.09.021},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19818804},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19818804},
    date-added = {2012-05-21 14:40:56},
    day = {08},
    doi = {10.1016/j.visres.2009.09.021},
    issn = {1878-5646},
    journal = {Vision Research},
    keywords = {assofield, perrinet11sfn},
    month = dec,
    number = {24},
    pages = {3001--3012},
    pmid = {19818804},
    priority = {0},
    title = {How do amplitude spectra influence rapid animal detection?},
    url = {http://dx.doi.org/10.1016/j.visres.2009.09.021},
    volume = {49},
    year = {2009}
}

@article{Bosking97,
    abstract = {Horizontal connections, formed primarily by the axon collaterals of pyramidal neurons in layer 2/3 of visual cortex, extend for millimeters parallel to the cortical surface and form patchy terminations. Previous studies have provided evidence that the patches formed by horizontal connections exhibit modular specificity, preferentially linking columns of neurons with similar response characteristics, such as preferred orientation. The issue of how these connections are distributed with respect to the topographic map of visual space, however, has not been resolved. Here we combine optical imaging of intrinsic signals with small extracellular injections of biocytin to assess quantitatively the specificity of horizontal connections with respect to both the map of orientation preference and the map of visual space in tree shrew V1. Our results indicate that horizontal connections outside a radius of 500 μm from the injection site exhibit not only modular specificity, but also specificity for axis of projection. Labeled axons extend for longer distances, and give off more terminal boutons, along an axis in the map of visual space that corresponds to the preferred orientation of the injection site. Inside of 500 μm, the pattern of connections is much less specific, with boutons found along every axis, contacting sites with a wide range of preferred orientations. The system of long-range horizontal connections can be summarized as preferentially linking neurons with co-oriented, co-axially aligned receptive fields. These observations suggest specific ways that horizontal circuits contribute to the response properties of layer 2/3 neurons and to mechanisms of visual perception.},
    author = {Bosking, William H. and Zhang, Y. and Schofield, B. and Fitzpatrick, D.},
    citeulike-article-id = {2953557},
    citeulike-linkout-0 = {http://www.jneurosci.org/cgi/content/abstract/17/6/2112},
    citeulike-linkout-1 = {http://www.jneurosci.org/content/17/6/2112.abstract},
    citeulike-linkout-2 = {http://www.jneurosci.org/content/17/6/2112.full.pdf},
    citeulike-linkout-3 = {http://www.jneurosci.org/cgi/content/abstract/17/6/2112},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/9045738},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=9045738},
    date-added = {2012-05-21 14:31:48},
    day = {15},
    issn = {1529-2401},
    journal = {Journal of Neuroscience},
    keywords = {assofield, bicv-sparse, kaplan13, perrinet11sfn},
    month = mar,
    number = {6},
    pages = {2112--2127},
    pmid = {9045738},
    priority = {0},
    publisher = {Society for Neuroscience},
    title = {Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex},
    url = {http://www.jneurosci.org/cgi/content/abstract/17/6/2112},
    volume = {17},
    year = {1997}
}

@article{Riesenhuber00,
    abstract = {Understanding how biological visual systems recognize objects is one of the ultimate goals in computational neuroscience. From the computational viewpoint of learning, different recognition tasks, such as categorization and identification, are similar, representing different trade-offs between specificity and invariance. Thus, the different tasks do not require different classes of models. We briefly review some recent trends in computational vision and then focus on feedforward, view-based models that are supported by psychophysical and physiological data.},
    address = {Department of Brain and Cognitive Sciences, McGovern Institute for Brain Research, Center for Biological and Computational Learning and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge 02142, USA.},
    author = {Riesenhuber, M. and Poggio, T.},
    citeulike-article-id = {2765643},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/81479},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/11127838},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=11127838},
    date-added = {2012-05-21 14:21:13},
    doi = {10.1038/81479},
    issn = {1097-6256},
    journal = {Nature Neuroscience},
    keywords = {assofield, categorization, perrinet11sfn},
    month = nov,
    pages = {1199--1204},
    pmid = {11127838},
    priority = {0},
    title = {Models of object recognition},
    url = {http://dx.doi.org/10.1038/81479},
    volume = {3 Suppl},
    year = {2000}
}

@article{Thorpe01,
    abstract = {It is generally believed that the acuity of the peripheral visual field is too poor to allow accurate object recognition and, that to be identified, most objects need to be brought into foveal vision by using saccadic eye movements. However, most measures of form vision in the periphery have been done at eccentricities below 10 degrees and have used relatively artificial stimuli such as letters, digits and compound Gabor patterns. Little is known about how such data would apply in the case of more naturalistic stimuli. Here humans were required to categorize briefly flashed (28 ms) unmasked photographs of natural scenes (39 degrees high, and 26 degrees across) on the basis of whether or not they contained an animal. The photographs appeared randomly in nine locations across virtually the entire extent of the horizontal visual field. Accuracy was 93.3\% for central vision and decreased almost linearly with increasing eccentricity (89.8\% at 13 degrees, 76.1\% at 44.5 degrees and 71.2\% at 57.5 degrees ). Even at the most extreme eccentricity, where the images were centred at 70.5 degrees, subjects scored 60.5\% correct. No evidence was found for hemispheric specialization. This level of performance was achieved despite the fact that the position of the image was unpredictable, ruling out the use of precued attention to target locations. The results demonstrate that even high-level visual tasks involving object vision can be performed using the relatively coarse information provided by the peripheral retina.},
    author = {Thorpe, Simon J. and Gegenfurtner, Karl R. and Fabre-Thorpe, Michele and Buelthoff, Heinrich H.},
    citeulike-article-id = {7737014},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11576191},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/11576191},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=11576191},
    date-added = {2012-05-21 14:15:50},
    issn = {0953-816X},
    journal = {European Journal of Neuroscience},
    keywords = {assofield, perrinet11sfn},
    month = sep,
    number = {5},
    pages = {869--876},
    pmid = {11576191},
    priority = {2},
    title = {Detection of animals in natural images using far peripheral vision},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11576191},
    volume = {14},
    year = {2001}
}

@article{Kirchner06,
    abstract = {Previous ultra-rapid go/no-go categorization studies with manual responses have demonstrated the remarkable speed and efficiency with which humans process natural scenes. Using a forced-choice saccade task we show here that when two scenes are simultaneously flashed in the left and right hemifields, human participants can reliably make saccades to the side containing an animal in as little as 120 ms. Low level differences between target and distractor images were unable to account for these exceptionally fast responses. The results suggest a very fast and unexpected route linking visual processing in the ventral stream with the programming of saccadic eye movements.},
    author = {Kirchner, Holle and Thorpe, Simon J.},
    citeulike-article-id = {10308682},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.visres.2005.10.002},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6T0W-4HJRRMP-3/2/2a36a561f62a7189fe81619174718a41},
    date-added = {2012-05-21 14:08:45},
    doi = {10.1016/j.visres.2005.10.002},
    issn = {0042-6989},
    journal = {Vision Research},
    keywords = {assofield, perrinet11sfn},
    number = {11},
    pages = {1762--1776},
    priority = {0},
    title = {Ultra-rapid object detection with saccadic eye movements: Visual processing speed revisited},
    url = {http://www.sciencedirect.com/science/article/B6T0W-4HJRRMP-3/2/2a36a561f62a7189fe81619174718a41},
    volume = {46},
    year = {2006}
}

@article{Hunter07,
    abstract = {Matplotlib is a {2D} graphics package for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
    address = {Los Alamitos, CA, USA},
    author = {Hunter, John D.},
    booktitle = {Computing in Science \& Engineering},
    citeulike-article-id = {2878517},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MCSE.2007.55},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.55},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/mcse.2007.55},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4160265},
    date-added = {2012-04-05 10:50:39},
    day = {01},
    doi = {10.1109/MCSE.2007.55},
    issn = {1521-9615},
    journal = {Computing in Science and Engineering},
    keywords = {assofield, bicv-motion, bicv-sparse, kaplan13, khoei13jpp, perrinet12pred, python, reproducible-science, thesis},
    month = may,
    number = {3},
    pages = {90--95},
    priority = {0},
    publisher = {IEEE Computer Society},
    title = {Matplotlib: A {2D} Graphics Environment},
    url = {http://dx.doi.org/10.1109/MCSE.2007.55},
    volume = {9},
    year = {2007}
}

@article{Oliphant07,
    abstract = {By itself, Python is an excellent "steering" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},
    address = {Los Alamitos, CA, USA},
    author = {Oliphant, T. E.},
    citeulike-article-id = {5662279},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MCSE.2007.58},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.58},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/mcse.2007.58},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4160250},
    date-added = {2012-04-05 10:49:45},
    day = {01},
    doi = {10.1109/MCSE.2007.58},
    institution = {Brigham Young Univ., Provo},
    issn = {1521-9615},
    journal = {Computing in Science and Engineering},
    keywords = {assofield, bicv-motion, bicv-sparse, kaplan13, khoei13jpp, perrinet12pred, python, reproducible-science, thesis},
    month = may,
    number = {3},
    pages = {10--20},
    priority = {0},
    publisher = {IEEE Computer Society},
    title = {Python for Scientific Computing},
    url = {http://dx.doi.org/10.1109/MCSE.2007.58},
    volume = {9},
    year = {2007}
}

@article{Hunt09,
    abstract = {Visual activity after eye-opening influences feature map structure in primary visual cortex (V1). For instance, rearing cats in an environment of stripes of one orientation yields an over-representation of that orientation in V1. However, whether such changes also affect the higher-order statistics of orientation maps is unknown. A statistical bias of orientation maps in normally raised animals is that the probability of the angular difference in orientation preference between each pair of points in the cortex depends on the angle of the line joining those points relative to a fixed but arbitrary set of axes. Natural images show an analogous statistical bias; however, whether this drives the development of comparable structure in V1 is unknown. We examined these statistics for normal, stripe-reared and dark-reared cats, and found that the biases present were not consistently related to those present in the input, or to genetic relationships. We compared these results with two computational models of orientation map development, an analytical model and a Hebbian model. The analytical model failed to reproduce the experimentally observed statistics. In the Hebbian model, while orientation difference statistics could be strongly driven by the input, statistics similar to those seen in experimental maps arose only when symmetry breaking was allowed to occur spontaneously. These results suggest that these statistical biases of orientation maps arise primarily spontaneously, rather than being governed by either input statistics or genetic mechanisms.},
    author = {Hunt, Jonathan J. and Giacomantonio, Clare E. and Tang, Huajin and Mortimer, Duncan and Jaffer, Sajjida and Vorobyov, Vasily and Ericksson, Geoffery and Sengpiel, Frank and Goodhill, Geoffrey J.},
    citeulike-article-id = {6850600},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.neuroimage.2009.03.052},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2712663/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19345738},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19345738},
    date-added = {2012-01-20 15:58:38},
    day = {1},
    doi = {10.1016/j.neuroimage.2009.03.052},
    issn = {1095-9572},
    journal = {NeuroImage},
    keywords = {area-v1, assofield, bicv-sparse, natural-scenes, perrinet11sfn},
    month = aug,
    number = {1},
    pages = {157--172},
    pmcid = {PMC2712663},
    pmid = {19345738},
    priority = {5},
    title = {Natural scene statistics and the structure of orientation maps in the visual cortex},
    url = {http://dx.doi.org/10.1016/j.neuroimage.2009.03.052},
    volume = {47},
    year = {2009}
}

@article{Hansen06a,
    author = {Hansen, Bruce C. and Hess, Robert F.},
    citeulike-article-id = {10247414},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/6.5.5},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/6/5/5.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/6/5/5.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/16881791},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=16881791},
    date-added = {2012-01-20 15:42:39},
    day = {26},
    doi = {10.1167/6.5.5},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {association\_field, assofield, contour, information, integration, log-gabor, perrinet11sfn, phase, sanz12jnp, segmentation, texture, vacher14},
    month = apr,
    number = {5},
    pmid = {16881791},
    priority = {2},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {The role of spatial phase in texture segmentation and contour integration},
    url = {http://dx.doi.org/10.1167/6.5.5},
    volume = {6},
    year = {2006}
}

@article{Sigman01,
    abstract = {To understand how the human visual system analyzes images, it is essential to know the structure of the visual environment. In particular, natural images display consistent statistical properties that distinguish them from random luminance distributions. We have studied the geometric regularities of oriented elements (edges or line segments) present in an ensemble of visual scenes, asking how much information the presence of a segment in a particular location of the visual scene carries about the presence of a second segment at different relative positions and orientations. We observed strong long-range correlations in the distribution of oriented segments that extend over the whole visual field. We further show that a very simple geometric rule, cocircularity, predicts the arrangement of segments in natural scenes, and that different geometrical arrangements show relevant differences in their scaling properties. Our results show similarities to geometric features of previous physiological and psychophysical studies. We discuss the implications of these findings for theories of early vision.},
    address = {Laboratory of Mathematical Physics, The Rockefeller University, 1230 York Avenue, New York, NY 10021, USA.},
    author = {Sigman, Mariano and Cecchi, Guillermo A. and Gilbert, Charles D. and Magnasco, Marcelo O.},
    citeulike-article-id = {984892},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.031571498},
    citeulike-linkout-1 = {http://www.pnas.org/content/98/4/1935.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/98/4/1935.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/11172054},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=11172054},
    date-added = {2012-01-20 15:34:01},
    day = {13},
    doi = {10.1073/pnas.031571498},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, bicv-sparse, chevron, cocircularity, natural-scenes, perrinet11sfn},
    month = feb,
    number = {4},
    pages = {1935--1940},
    pmid = {11172054},
    priority = {5},
    publisher = {National Academy of Sciences},
    title = {On a common circle: Natural scenes and {G}estalt rules},
    url = {http://dx.doi.org/10.1073/pnas.031571498},
    volume = {98},
    year = {2001}
}

@article{Hunt11,
    abstract = {The statistical structure of the visual world offers many useful clues for understanding how biological visual systems may understand natural scenes. One particularly important early process in visual object recognition is that of grouping together edges which belong to the same contour. The layout of edges in natural scenes have strong statistical structure. One such statistical property is that edges tend to lie on a common circle, and this 'co-circularity' can predict human performance at contour grouping. We therefore tested the hypothesis that long-range excitatory lateral connections in the primary visual cortex, which are believed to be involved in contour grouping, display a similar co-circular structure. By analyzing data from tree shrews, where information on both lateral connectivity and the overall structure of the orientation map was available, we found a surprising diversity in the relevant statistical structure of the connections. In particular, the extent to which co-circularity was displayed varied significantly. Overall, these data suggest the intriguing possibility that V1 may contain both co-circular and anti-cocircular connections.},
    author = {Hunt, Jonathan J. and Bosking, William H. and Goodhill, Geoffrey J.},
    citeulike-article-id = {10247393},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/2042-1001-1-3},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3269092/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22330062},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22330062},
    date-added = {2012-01-20 15:24:54},
    doi = {10.1186/2042-1001-1-3},
    issn = {2042-1001},
    journal = {Neural Systems \& Circuits},
    keywords = {area-v1, assofield, bicv-sparse, lateral\_connections, perrinet11sfn},
    number = {1},
    pages = {3+},
    pmcid = {PMC3269092},
    pmid = {22330062},
    priority = {2},
    title = {Statistical structure of lateral connections in the primary visual cortex},
    url = {http://dx.doi.org/10.1186/2042-1001-1-3},
    volume = {1},
    year = {2011}
}

@article{Crouzet11a,
    abstract = {Recent experimental work has demonstrated the existence of extremely rapid saccades toward faces in natural scenes that can be initiated only 100\^{a}ms after image onset (Crouzet et al., 2010). These ultra-rapid saccades constitute a major challenge to current models of processing in the visual system because they do not seem to leave enough time for even a single feed-forward pass through the ventral stream. Here we explore the possibility that the information required to trigger these very fast saccades could be extracted very early on in visual processing using relatively low-level amplitude spectrum ({AS}) information in the Fourier domain. Experiment 1 showed that {AS} normalization can significantly alter face-detection performance. However, a decrease of performance following {AS} normalization does not alone prove that {AS}-based information is used (Gaspar and Rousselet, 2009). In Experiment 2, following the Gaspar and Rousselet paper, we used a swapping procedure to clarify the role of {AS} information in fast object detection. Our experiment is composed of three conditions: (i) original images, (ii) category swapped, in which the face image has the {AS} of a vehicle, and the vehicle has the {AS} of a face, and (iii) identity swapped, where the face has the {AS} of another face image, and the vehicle has the {AS} of another vehicle image. The results showed very similar levels of performance in the original and identity swapped conditions, and a clear drop in the category swapped condition. This result demonstrates that, in the early temporal window offered by the saccadic choice task, the visual saccadic system does indeed rely on low-level {AS} information in order to rapidly detect faces. This sort of crude diagnostic information could potentially be derived very early on in the visual system, possibly as early as V1 and V2.},
    author = {Crouzet, S\'{e}bastien and Thorpe, Simon J.},
    citeulike-article-id = {10110341},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fpsyg.2011.00342},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3221302/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22125544},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22125544},
    date-added = {2011-12-09 14:26:38},
    doi = {10.3389/fpsyg.2011.00342},
    issn = {1664-1078},
    journal = {Frontiers in Psychology},
    keywords = {assofield, contour, perrinet11sfn, rank\_order, ultra\_fast},
    pages = {342+},
    pmcid = {PMC3221302},
    pmid = {22125544},
    priority = {2},
    title = {Low-level cues and ultra-fast face detection},
    url = {http://dx.doi.org/10.3389/fpsyg.2011.00342},
    volume = {2},
    year = {2011}
}

@article{Field93,
    abstract = {The Gestalt law of "good continuation" has been used to describe a variety of phenomena demonstrating the importance of continuity in human perception. In this study, we consider how continuity may be represented by a visual system that filters spatial data using arrays of cells selective for orientation and spatial frequency. Many structures (e.g. fractal contours) show a form of redundancy which is well represented by the continuity of features as they vary across space and frequency. We suggest that it is possible to take advantage of the redundancy in continuous, but non-aligned features by associating the outputs of filters with similar tuning. Five experiments were performed, to determine the rules that govern the perception of continuity. Observers were presented with arrays of oriented, band-pass elements (Gabor patches) in which a subset of the elements was aligned along a "jagged" path. Using a forced-choice procedure, observers were found to be capable of identifying the path within a field of randomly-oriented elements even when the spacing between the elements was considerably larger than the size of any of the individual elements. Furthermore, when the elements were oriented at angles up to +/- 60 deg relative to one another, the path was reliably identified. Alignment of the elements along the path was found to play a large role in the ability to detect the path. Small variations in the alignment or aligning the elements orthogonally (i.e. "side-to-side" as opposed to "end-to-end") significantly reduced the observer's ability to detect the presence of a path. The results are discussed in terms of an "association field" which integrates information across neighboring filters tuned to similar orientations. We suggest that some of the processes involved in texture segregation may have a similar explanation.},
    address = {Department of Psychology, Cornell University, Ithaca, NY 14853.},
    author = {Field, David J. and Hayes, A. and Hess, R. F.},
    citeulike-article-id = {554717},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0042-6989(93)90156-Q},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/8447091},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/8447091},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=8447091},
    date-added = {2011-11-09 13:31:23},
    doi = {10.1016/0042-6989(93)90156-Q},
    issn = {0042-6989},
    journal = {Vision {R}esearch},
    keywords = {association\_field, assofield, bicv-sparse, contour, contour-grouping, perrinet11sfn},
    month = jan,
    number = {2},
    pages = {173--193},
    pmid = {8447091},
    priority = {3},
    title = {Contour integration by the human visual system: evidence for a local "association field"},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/8447091},
    volume = {33},
    year = {1993}
}

@article{Choe04,
    abstract = {Contour integration in low-level vision is believed to occur based on lateral interaction between neurons with similar orientation tuning. How such interactions could arise in the brain has been an open question. Our model suggests that the interactions can be <i>learned</i> through input-driven self-organization, i.e. through the same mechanism that underlies many other developmental and functional phenomena in the visual cortex. The model also shows how synchronized firing mediated by these lateral connections can represent the percept of a contour, resulting in performance similar to that of human contour integration. The model further demonstrates that contour integration performance can differ in different parts of the visual field, depending on what kinds of input distributions they receive during development. The model thus grounds an important perceptual phenomenon onto detailed neural mechanisms, so that various structural and functional properties can be measured, and predictions can be made to guide future experiments.},
    author = {Choe, Yoonsuck and Miikkulainen, Risto},
    citeulike-article-id = {10007310},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00422-003-0435-5},
    citeulike-linkout-1 = {http://z.cs.utexas.edu/users/ai-lab/pub-view.php?PubID=142},
    citeulike-linkout-2 = {http://z.cs.utexas.edu/users/ai-lab/pub-view.php?PubID=142},
    citeulike-linkout-3 = {http://cs.utexas.edu/users/ai-lab/pub-view.php?PubID=142},
    citeulike-linkout-4 = {http://cs.utexas.edu/\~{}ai-lab/pub-view.php?PubID=142},
    citeulike-linkout-5 = {http://nn.cs.utexas.edu/pub-view.php?PubID=142},
    date-added = {2011-11-09 13:28:29},
    day = {1},
    doi = {10.1007/s00422-003-0435-5},
    issn = {1432-0770},
    journal = {Biological Cybernetics},
    keywords = {assofield, lateral\_connections, perrinet11sfn, topographic\_maps},
    month = feb,
    number = {2},
    pages = {75--88},
    priority = {3},
    title = {Contour integration and segmentation with self-organized lateral connections},
    url = {http://z.cs.utexas.edu/users/ai-lab/pub-view.php?PubID=142},
    volume = {90},
    year = {2004}
}

@article{Callaway90,
    abstract = {Pyramidal cells in layer 2/3 of adult cat striate cortex have long, intrinsic horizontal axon collaterals within both layer 2/3 and layer 5. These collaterals form periodic "clusters" of finer axon branches that link columns of similar orientation selectivity. We have investigated the sequence of events and possible mechanisms underlying the development of these clustered intrinsic horizontal connections using a combination of neuronal tracers and intracellular staining. Small injections of fluorescent latex microspheres made during the first postnatal week (at P4-6), when examined in tangential sections, produced an even, unclustered distribution of retrogradely labeled cells up to 2 mm from the injection site. At P8, retrograde labeling extended over a larger area and clustering was discernible, primarily among the most distant labeled cells. At both P6 and P8, labeling was similar in layers 2/3 and 5, indicating that the transition from clustered to unclustered connections occurred simultaneously for cells in superficial and deep laminae. By the end of the second postnatal week (P12-15), retrogradely labeled cells were far more clustered both within and beyond the extent of P6 label; the density of labeled cells was high throughout the labeled region, but much higher within clusters. The periodicity of these nascent clusters was similar to that in the adult. Despite obvious clustering, the pattern of retrograde label observed following injections at 2-3 weeks (P12-21) differed markedly from the adult, in that the regions between clusters contained many labeled cells. Over the next 3 weeks, the connections were refined, so that by the sixth postnatal week (P36-38), regions between clusters contained very few retrogradely labeled cells and the overall pattern of retrograde label was indistinguishable from that in adults. Despite differences in postmigratory ages of neurons from the superficial and deep laminae, clustering of retrogradely labeled cells from these 2 populations was similar at all ages. Experiments in which 2-3 weeks elapsed between the time microsphere injections were made and animals were killed demonstrated that neither the initial formation of crude clusters nor their refinement was due to cell death. Instead, cluster refinement resulted from specific process elimination. When a red microsphere injection at P15 was followed by a green microsphere injection at exactly the same location on P29, the earlier injection resulted in crude clustering, as expected. Virtually all of the cells double-labeled by the later injection were within the densest clusters of label from the early {injection.(ABSTRACT} {TRUNCATED} {AT} 400 {WORDS})},
    author = {Callaway, E. M. and Katz, L. C.},
    citeulike-article-id = {4374038},
    citeulike-linkout-0 = {http://www.jneurosci.org/cgi/content/abstract/10/4/1134},
    citeulike-linkout-1 = {http://www.jneurosci.org/cgi/content/abstract/10/4/1134},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/2329372},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=2329372},
    date-added = {2011-11-09 13:22:35},
    day = {1},
    issn = {0270-6474},
    journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
    keywords = {area-v1, assofield, cat, lateral\_connections, perrinet11sfn},
    month = apr,
    number = {4},
    pages = {1134--1153},
    pmid = {2329372},
    priority = {2},
    title = {Emergence and refinement of clustered horizontal connections in cat striate cortex.},
    url = {http://www.jneurosci.org/cgi/content/abstract/10/4/1134},
    volume = {10},
    year = {1990}
}

@article{Burn08,
    abstract = {This review of rat sensory perception spans eight decades of work conducted across diverse research fields. It covers rat vision, audition, olfaction, gustation, and somatosensation, and describes how rat perception differs from and coincides with ours. As Nagel's seminal work (1974) implies, we cannot truly know what it is like to be a rat, but we can identify and acknowledge their perceptual biases. These primarily nocturnal rodents are extremely sensitive to light, with artificial lighting frequently causing retinal degeneration, and their vision extends into the ultraviolet. Their olfactory sensitivity and ultrasonic hearing means they are influenced by environmental factors and conspecific signals that we cannot perceive. Rat and human gustation are similar, being opportunistic omnivores, yet this sense becomes largely redundant in the laboratory, where rodents typically consume a single homogenous diet. Rat somatosensation differs from ours in their thigmotactic tendencies and highly sensitive, specialised vibrissae. Knowledge of species-specific perceptual abilities can enhance experimental designs, target resources, and improve animal welfare. Furthermore, the sensory environment has influences from neurone to behaviour, so it can not only affect the senses directly, but also behaviour, health, physiology, and neurophysiology. Research shows that environmental enrichment is necessary for normal visual, auditory, and somatosensory development. Laboratory rats are not quite the simple, convenient models they are sometimes taken for; although very adaptable, they are complex mammals existing in an environment they are not evolutionarily adapted for. Here, many important implications of rat perception are highlighted, and suggestions are made for refining experiments and housing.},
    author = {Burn, C.},
    citeulike-article-id = {9948179},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.applanim.2008.02.007},
    date-added = {2011-10-26 15:26:00},
    doi = {10.1016/j.applanim.2008.02.007},
    issn = {01681591},
    journal = {Applied Animal Behaviour Science},
    keywords = {assofield, natural-scenes, perrinet11sfn},
    month = jul,
    number = {1-2},
    pages = {1--32},
    priority = {5},
    title = {What is it like to be a rat? Rat sensory perception and its implications for experimental design and rat welfare},
    url = {http://dx.doi.org/10.1016/j.applanim.2008.02.007},
    volume = {112},
    year = {2008}
}

@article{Cha02,
    abstract = {A distance measure between two histograms has applications in feature selection, image indexing and retrieval, pattern classification and clustering, etc. We propose a distance between sets of measurement values as a measure of dissimilarity of two histograms. The proposed measure has the advantage over the traditional distance measures regarding the overlap between two distributions; it takes the similarity of the non-overlapping parts into account as well as that of overlapping parts. We consider three versions of the univariate histogram, corresponding to whether the type of measurement is nominal, ordinal, and modulo and their computational time complexities are \^{I}\^{A}(b), \^{I}\^{A}(b) and O(b2) for each type of measurements, respectively, where b is the number of levels in histograms.},
    author = {Cha, Sung-Hyuk and Srihari, Sargur N.},
    citeulike-article-id = {579526},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0031-3203(01)00118-2},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V14-457VJDT-F/2/928405f14b7e9a8f75a58303db9e72d0},
    comment = { * review different histogram norms / the modulo norm I did not knew
 * lacks a more real-life application of their different applications
---=note-separator=---
* review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications
---=note-separator=---
* review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications
---=note-separator=---
* review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications
---=note-separator=---
* review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications ---=note-separator=--- * review different histogram norms / the modulo norm I did not knew * lacks a more real-life application of their different applications},
    date-added = {2011-10-17 11:34:47},
    doi = {10.1016/s0031-3203(01)00118-2},
    issn = {00313203},
    journal = {Pattern Recognition},
    keywords = {assofield, classification, perrinet11sfn},
    month = jun,
    number = {6},
    pages = {1355--1370},
    priority = {5},
    title = {On measuring the distance between histograms},
    url = {http://dx.doi.org/10.1016/s0031-3203(01)00118-2},
    volume = {35},
    year = {2002}
}

@article{Torralba03,
    abstract = {In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image. In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image.},
    author = {Torralba, Antonio and Oliva, Aude},
    booktitle = {Network: Computation in Neural Systems},
    citeulike-article-id = {9885654},
    citeulike-linkout-0 = {http://dx.doi.org/10.1088/0954-898x\_14\_3\_302},
    citeulike-linkout-1 = {http://www.informahealthcare.com/doi/abs/10.1088/0954-898X\_14\_3\_302},
    date-added = {2011-10-10 09:28:18},
    day = {1},
    doi = {10.1088/0954-898x\_14\_3\_302},
    journal = {Network},
    keywords = {association\_field, assofield, categorization, natural, natural-scenes, perrinet11sfn, sanz12jnp, statistics, vacher14},
    month = jan,
    number = {3},
    pages = {391--412},
    priority = {2},
    publisher = {Informa Clin Med},
    title = {Statistics of natural image categories},
    url = {http://dx.doi.org/10.1088/0954-898x\_14\_3\_302},
    volume = {14},
    year = {2003}
}

@article{Wannig11,
    abstract = {Visual attention can select spatial locations, features and objects. Theories of object-based attention claim that attention enhances the representation of all parts of an object, even parts that are not task relevant. We recorded neuronal activity in area V1 of macaque monkeys and observed an automatic spread of attention to image elements outside of the attentional focus when they were bound to an attended stimulus by Gestalt criteria. {\\copyright} 2011 Nature America, Inc. All rights reserved.},
    author = {Wannig, Aurel and Stanisor, Liviu and Roelfsema, Pieter R.},
    citeulike-article-id = {9820111},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.2910},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.2910},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/21926984},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=21926984},
    date-added = {2011-10-03 09:36:06},
    day = {18},
    doi = {10.1038/nn.2910},
    issn = {1546-1726},
    journal = {Nature neuroscience},
    keywords = {area-v1, assofield, attention, gestalt},
    month = sep,
    number = {10},
    pages = {1243--1244},
    pmid = {21926984},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Automatic spread of attentional response modulation along Gestalt criteria in primary visual cortex.},
    url = {http://dx.doi.org/10.1038/nn.2910},
    volume = {14},
    year = {2011}
}

@article{Girshick11,
    abstract = {Humans are good at performing visual tasks, but experimental measurements have revealed substantial biases in the perception of basic visual attributes. An appealing hypothesis is that these biases arise through a process of statistical inference, in which information from noisy measurements is fused with a probabilistic model of the environment. However, such inference is optimal only if the observer's internal model matches the environment. We found this to be the case. We measured performance in an orientation-estimation task and found that orientation judgments were more accurate at cardinal (horizontal and vertical) orientations. Judgments made under conditions of uncertainty were strongly biased toward cardinal orientations. We estimated observers' internal models for orientation and found that they matched the local orientation distribution measured in photographs. In addition, we determined how a neural population could embed probabilistic information responsible for such biases.},
    author = {Girshick, Ahna R. and Landy, Michael S. and Simoncelli, Eero P.},
    citeulike-article-id = {9459186},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nn.2831},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn.2831},
    citeulike-linkout-2 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3125404/},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/21642976},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=21642976},
    date-added = {2011-09-20 15:34:04},
    day = {05},
    doi = {10.1038/nn.2831},
    issn = {1546-1726},
    journal = {Nature {N}euroscience},
    keywords = {assofield, bicv-sparse, natural-scenes, perrinet11sfn, prior\_probability},
    month = jul,
    number = {7},
    pages = {926--932},
    pmcid = {PMC3125404},
    pmid = {21642976},
    priority = {2},
    publisher = {Reserved.},
    title = {Cardinal rules: visual orientation perception reflects knowledge of environmental statistics},
    url = {http://dx.doi.org/10.1038/nn.2831},
    volume = {14},
    year = {2011}
}

@article{Hess03,
    author = {Hess, R. F. and Hayes, A. and Field, D. J.},
    citeulike-article-id = {9562724},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jphysparis.2003.09.013},
    date-added = {2011-07-19 14:56:38},
    doi = {10.1016/j.jphysparis.2003.09.013},
    journal = {J. Physiol. Paris},
    keywords = {association\_field, assofield, contour, discrimination, integration, perrinet11sfn, sanz12jnp, segmentation, texture, vacher14},
    number = {2-3},
    pages = {105--119},
    priority = {2},
    title = {Contour integration and cortical processing},
    url = {http://dx.doi.org/10.1016/j.jphysparis.2003.09.013},
    volume = {97},
    year = {2003}
}

@article{Walther11,
    abstract = {Humans are remarkably efficient at categorizing natural scenes. In fact, scene categories can be decoded from functional {MRI} ({fMRI}) data throughout the ventral visual cortex, including the primary visual cortex, the parahippocampal place area ({PPA}), and the retrosplenial cortex ({RSC}). Here we ask whether, and where, we can still decode scene category if we reduce the scenes to mere lines. We collected {fMRI} data while participants viewed photographs and line drawings of beaches, city streets, forests, highways, mountains, and offices. Despite the marked difference in scene statistics, we were able to decode scene category from {fMRI} data for line drawings just as well as from activity for color photographs, in primary visual cortex through {PPA} and {RSC}. Even more remarkably, in {PPA} and {RSC}, error patterns for decoding from line drawings were very similar to those from color photographs. These data suggest that, in these regions, the information used to distinguish scene category is similar for line drawings and photographs. To determine the relative contributions of local and global structure to the human ability to categorize scenes, we selectively removed long or short contours from the line drawings. In a category-matching task, participants performed significantly worse when long contours were removed than when short contours were removed. We conclude that global scene structure, which is preserved in line drawings, plays an integral part in representing scene categories.},
    author = {Walther, Dirk B. and Chai, Barry and Caddigan, Eamon and Beck, Diane M. and Fei-Fei, Li},
    citeulike-article-id = {9456881},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.1015666108},
    citeulike-linkout-1 = {http://www.pnas.org/content/108/23/9661.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/108/23/9661.full.pdf},
    citeulike-linkout-3 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3111263/},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/21593417},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=21593417},
    date-added = {2011-06-26 22:52:36},
    day = {07},
    doi = {10.1073/pnas.1015666108},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {assofield, natural-scenes, representation},
    month = jun,
    number = {23},
    pages = {9661--9666},
    pmcid = {PMC3111263},
    pmid = {21593417},
    priority = {2},
    publisher = {National Academy of Sciences},
    title = {Simple line drawings suffice for functional {MRI} decoding of natural scene categories},
    url = {http://dx.doi.org/10.1073/pnas.1015666108},
    volume = {108},
    year = {2011}
}

@article{Oliva01,
    author = {Oliva, Aude and Torralba, Antonio},
    citeulike-article-id = {9447889},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1011139631724},
    date-added = {2011-06-22 10:47:34},
    doi = {10.1023/A:1011139631724},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {assofield, images, natural, natural-scenes, sanz12jnp, statisticsfourier, vacher14},
    number = {3},
    pages = {145--175},
    priority = {0},
    title = {Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope},
    url = {http://dx.doi.org/10.1023/A:1011139631724},
    volume = {42},
    year = {2001}
}

@article{Karklin08,
    abstract = {A fundamental function of the visual system is to encode the building blocks of natural scenes---edges, textures and shapes---that subserve visual tasks such as object recognition and scene understanding. Essential to this process is the formation of abstract representations that generalize from specific instances of visual input. A common view holds that neurons in the early visual system signal conjunctions of image features1, 2, but how these produce invariant representations is poorly understood. Here we propose that to generalize over similar images, higher-level visual neurons encode statistical variations that characterize local image regions. We present a model in which neural activity encodes the probability distribution most consistent with a given image. Trained on natural images, the model generalizes by learning a compact set of dictionary elements for image distributions typically encountered in natural scenes. Model neurons show a diverse range of properties observed in cortical cells. These results provide a new functional explanation for nonlinear effects in complex cells3, 4, 5, 6 and offer insight into coding strategies in primary visual cortex (V1) and higher visual areas.},
    author = {Karklin, Yan and Lewicki, Michael S.},
    citeulike-article-id = {3681664},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature07481},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature07481},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19020501},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19020501},
    date-added = {2011-06-21 16:40:26},
    day = {19},
    doi = {10.1038/nature07481},
    issn = {1476-4687},
    journal = {Nature},
    keywords = {assofield, complex-cells, emergence, hierarchical\_model, sparse},
    month = nov,
    number = {7225},
    pages = {83--86},
    pmid = {19020501},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Emergence of complex cell properties by learning to generalize in natural scenes},
    url = {http://dx.doi.org/10.1038/nature07481},
    volume = {457},
    year = {2008}
}

@incollection{Garrigues08,
    abstract = {It has been shown that adapting a dictionary of basis functions to the statistics of natural images so as to maximize sparsity in the coefficients results in a set of dictionary elements whose spatial properties resemble those of V1 (primary visual cortex) receptive fields. However, the resulting sparse coefficients still exhibit pronounced statistical dependencies, thus violating the independence assumption of the sparse coding model. Here, we propose a model that attempts to capture the dependencies among the basis function coefficients by including a pairwise coupling term in the prior over the coefficient activity states. When adapted to the statistics of natural images, the coupling terms learn a combination of facilitatory and inhibitory interactions among neighboring basis functions. These learned interactions may offer an explanation for the function of horizontal connections in V1, and we discuss the implications of our findings for physiological experiments.},
    address = {Cambridge, MA, USA},
    author = {Garrigues, Pierre J. and Olshausen, Bruno A.},
    booktitle = {Advances in Neural Information Processing Systems 20},
    citeulike-article-id = {3905384},
    date-added = {2011-06-21 16:33:20},
    editor = {Platt, J. C. and Koller, D. and Singer, Y. and Roweis, S.},
    keywords = {association\_field, assofield, lateral\_connections, perrinet11sfn},
    pages = {505--512},
    priority = {5},
    publisher = {MIT Press},
    title = {Learning Horizontal Connections in a Sparse Coding Model of Natural Images},
    year = {2008}
}

@article{Fischer07cv,
    abstract = {Abstract--- {M}eanwhile biorthogonal wavelets got a very popu- lar image processing tool, alternative multiresolution transforms have been proposed for solving some of their drawbacks, namely the poor selectivity in orientation and the lack of translation in- variance due to the aliasing between subbands. {T}hese transforms are generally overcomplete and consequently offer huge degrees of freedom in their design. {A}t the same time their optimization get a challenging task. {W}e proposed here a log-{G}abor wavelet transform gathering the excellent mathematical properties of the {G}abor functions with a carefully construction to maintain the properties of the filters and to permit exact reconstruction. {T}wo major improvements are proposed: first the highest frequency bands are covered by narrowly localized oriented filters. {A}nd second, all the frequency bands including the highest and lowest frequencies are uniformly covered so as exact reconstruction is achieved using the same filters in both the direct and the inverse transforms (which means that the transform is self-invertible). {T}he transform is optimized not only mathematically but it also follows as much as possible the knowledge on the receptive field of the simple cells of the {P}rimary {V}isual {C}ortex ({V}1) of primates and on the statistics of natural images. {C}ompared to the state of the art, the log-{G}abor wavelets show excellent behavior in their ability to segregate the image information (e.g. the contrast edges) from incoherent {G}aussian noise by hard thresholding and to code the image features through a reduced set of coefficients with large magnitude. {S}uch characteristics make the transform a promising tool for general image processing tasks.},
    address = {Hingham, MA, USA},
    author = {Fischer, Sylvain and Sroubek, Filip and Perrinet, Laurent U. and Redondo, Rafael and Crist{\'{o}}bal, Gabriel},
    citeulike-article-id = {2902016},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1286000.1286006},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-006-0026-8},
    date-added = {2011-05-18 09:12:21},
    day = {13},
    doi = {10.1007/s11263-006-0026-8},
    issn = {1573-1405},
    journal = {International Journal of Computer Vision},
    keywords = {assofield, bicv-sparse, denoising, filters, high-pass, image, log-gabor, motion-clouds, oriented, perrinet11sfn, sanz12jnp, system, transforms, vacher14, vision, wavelet, wavelets},
    month = jan,
    number = {2},
    pages = {231--246},
    priority = {0},
    publisher = {Kluwer Academic Publishers},
    title = {Self-invertible 2{D} log-{G}abor wavelets},
    url = {http://dx.doi.org/10.1007/s11263-006-0026-8},
    volume = {75},
    year = {2007}
}

@article{Voges10neurocomp,
    abstract = {We study cortical network dynamics for a spatially embedded network model. It represents, in terms of spatial scale, a large piece of cortex allowing for long-range connections, resulting in a rather sparse connectivity. The spatial embedding also permits us to include distance-dependent conduction delays. We use two different types of conductance-based {I\&F} neurons as excitatory and inhibitory units, as well as specific connection probabilities. In order to remain computationally tractable, we reduce neuron density, modelling part of the missing internal input via external poissonian spike trains. Compared to previous studies, we observe significant changes in the dynamical phase space: Altered activity patterns require another regularity measures than the coefficient of variation. Hence, we compare three different regularity measure on the basis of artificial inter-spike-interval distributions. We identify two types of mixed states, where different phases coexist in certain regions of the phase space. More notably, our boundary between high and low activity states depends predominantly on the relation between excitatory and inhibitory synaptic strength instead of the input rate.},
    author = {Voges, Nicole and Perrinet, Laurent},
    citeulike-article-id = {6193755},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jphysparis.2009.11.004},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19909813},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19909813},
    date-added = {2011-05-18 09:10:09},
    day = {10},
    doi = {10.1016/j.jphysparis.2009.11.004},
    issn = {0928-4257},
    journal = {Journal of Physiology-Paris},
    keywords = {area-v1, association\_field, assofield, decoding, perrinet11sfn},
    month = jan,
    number = {1-2},
    pages = {51--60},
    pmid = {19909813},
    priority = {0},
    title = {Phase space analysis of networks based on biologically realistic parameters},
    url = {http://dx.doi.org/10.1016/j.jphysparis.2009.11.004},
    volume = {104},
    year = {2010}
}

@article{Field87,
    author = {Field, David J.},
    citeulike-article-id = {9277525},
    date-added = {2011-05-11 17:27:47},
    journal = {Journal of {O}ptical {S}ociety of {A}merica, {A}},
    keywords = {assofield, bicv-sparse, images, motion-clouds, natural, natural-scenes, perrinet11sfn, sanz12jnp, vacher14},
    number = {12},
    pages = {2379--94},
    priority = {5},
    title = {Relations between the statistics of natural images and the response properties of cortical cells},
    volume = {4},
    year = {1987}
}

@article{Oppenheim81,
    author = {Oppenheim, A. and Lim, J.},
    citeulike-article-id = {9277496},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/PROC.1981.12022},
    comment = {says that you can still recognize the form of an image if you dicard the amplitude spectra, while keeping the phase},
    date-added = {2011-05-11 17:27:44},
    doi = {10.1109/PROC.1981.12022},
    issn = {0018-9219},
    journal = {Proceedings of the IEEE},
    keywords = {assofield, motion-clouds, perrinet11sfn, phase, sanz12jnp, vacher14},
    number = {5},
    pages = {529--541},
    priority = {2},
    title = {The importance of phase in signals},
    url = {http://dx.doi.org/10.1109/PROC.1981.12022},
    volume = {69},
    year = {1981}
}

@article{Motoyoshi10,
    abstract = {The present study analyzes the effect of local pairwise orientation relations on the perception of textural structure. We have employed a new class of stochastic stimuli comprised of paired Gabor patches with a particular orientation difference ( \^{I}¸) and relative angular position ( \"{I}). We measured the threshold proportion of signal pairs for discriminating the target texture from a noise texture comprised of randomly oriented pairs. The results showed that observers were sensitive not only to textures containing pairs with curvilinear configurations such as lines and curves ( \"{I} = \^{I}¸ / 2), but also to their orthogonal configurations such as V shapes and parallels ( \"{I} = \^{I}¸ / 2 + 90). Both classes of configuration exhibit the property of co-circularity, a fundamental geometric feature of edges and contours in natural images. We also found higher sensitivity for textures made from orientation pairs with either large or small orientation differences. These results suggest that in addition to orientation difference, co-circularity plays a critical role in the perception of orientation-based textural structure.},
    author = {Motoyoshi, Isamu and Kingdom, Frederick A. A.},
    citeulike-article-id = {9275242},
    citeulike-linkout-0 = {http://dx.doi.org/10.1167/10.1.3},
    citeulike-linkout-1 = {http://www.journalofvision.org/content/10/1/3.abstract},
    citeulike-linkout-2 = {http://www.journalofvision.org/content/10/1/3.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/21216761},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=21216761},
    date-added = {2011-05-11 13:56:18},
    day = {11},
    doi = {10.1167/10.1.3},
    issn = {1534-7362},
    journal = {Journal of Vision},
    keywords = {assofield, edge\_co-occurrence, perrinet11sfn},
    month = jan,
    number = {1},
    pages = {3+},
    pmid = {21216761},
    priority = {0},
    publisher = {Association for Research in Vision and Ophthalmology},
    title = {The role of co-circularity of local elements in texture perception},
    url = {http://dx.doi.org/10.1167/10.1.3},
    volume = {10},
    year = {2010}
}

@article{Samonds06,
    abstract = {We explored how contour information in primary visual cortex might be embedded in the simultaneous activity of multiple cells recorded with a 100-electrode array. Synchronous activity in cat visual cortex was more selective and predictable in discriminating between drifting grating and concentric ring stimuli than changes in firing rate. Synchrony was found even between cells with wholly different orientation preferences when their receptive fields were circularly aligned, and membership in synchronous groups was orientation and curvature dependent. The existence of synchrony between cocircular cells reinforces its role as a general mechanism for contour integration and shape detection as predicted by association field concepts. Our data suggest that cortical synchrony results from common and synchronous input from earlier visual areas and that it could serve to shape extrastriate response selectivity.},
    author = {Samonds, Jason M. and Zhou, Zhiyi and Bernard, Melanie R. and Bonds, A. B.},
    citeulike-article-id = {3470292},
    citeulike-linkout-0 = {http://dx.doi.org/10.1152/jn.01070.2005},
    citeulike-linkout-1 = {http://jn.physiology.org/content/95/4/2602.abstract},
    citeulike-linkout-2 = {http://jn.physiology.org/content/95/4/2602.full.pdf},
    citeulike-linkout-3 = {http://jn.physiology.org/cgi/content/abstract/95/4/2602},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/16354730},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=16354730},
    date-added = {2011-05-11 13:55:46},
    day = {1},
    doi = {10.1152/jn.01070.2005},
    journal = {Journal of Neurophysiology},
    keywords = {association\_field, assofield, curvature, edge\_co-occurrence, perrinet11sfn},
    month = apr,
    number = {4},
    pages = {2602--2616},
    pmid = {16354730},
    priority = {2},
    title = {Synchronous Activity in Cat Visual Cortex Encodes Collinear and Cocircular Contours},
    url = {http://dx.doi.org/10.1152/jn.01070.2005},
    volume = {95},
    year = {2006}
}

@article{Parent89,
    abstract = {An approach is described for curve inference that is based on curvature information. The inference procedure is divided into two stages: a trace inference stage, which is the subject of the present work, and a curve synthesis stage. It is shown that recovery of the trace of a curve requires estimating local models for the curve at the same time, and that tangent and curvature information are sufficient. These make it possible to specify powerful constraints between estimated tangents to a curve, in terms of a neighborhood relationship called cocircularity, and between curvature estimates, in terms of a curvature consistency relation. Because all curve information is quantized, special care must be taken to obtain accurate estimates of trace points, tangents, and curvatures. This issue is addressed specifically to the introduction of a smoothness constraint and a maximum curvature constraint. The procedure is applied to two types of images: artificial images designed to evaluate curvature and noise sensitivity, and natural images},
    address = {Los Alamitos, CA, USA},
    author = {Parent, P. and Zucker, S. W.},
    citeulike-article-id = {6926649},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/34.31445},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/34.31445},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=31445},
    date-added = {2011-05-11 13:54:22},
    doi = {10.1109/34.31445},
    issn = {01628828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {association\_field, assofield, curvature, perrinet11sfn},
    month = aug,
    number = {8},
    pages = {823--839},
    priority = {4},
    publisher = {IEEE Computer Society},
    title = {Trace inference, curvature consistency, and curve detection},
    url = {http://dx.doi.org/10.1109/34.31445},
    volume = {11},
    year = {1989}
}

@article{Rao99,
    abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
    author = {Rao, Rajesh and Ballard, Dana},
    citeulike-article-id = {270924},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/4580},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nn0199\_79},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/10195184},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=10195184},
    comment = {This is a paper about application of Kalman filters.},
    date-added = {2011-04-14 10:36:57},
    day = {1},
    doi = {10.1038/4580},
    issn = {1097-6256},
    journal = {Nature {N}euroscience},
    keywords = {assofield, bayesian, bicv-motion, bicv-sparse, hierarchical\_model, kaplan13, perrinet11sfn, perrinetadamsfriston14, thesis},
    month = jan,
    number = {1},
    pages = {79--87},
    pmid = {10195184},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
    url = {http://dx.doi.org/10.1038/4580},
    volume = {2},
    year = {1999}
}

@article{Perrinet10shl,
    abstract = {Neurons in the input layer of primary visual cortex in primates develop edge-like receptive fields. One approach to understanding the emergence of this response is to state that neural activity has to efficiently represent sensory data with respect to the statistics of natural scenes. Furthermore, it is believed that such an efficient coding is achieved using a competition across neurons so as to generate a sparse representation, that is, where a relatively small number of neurons are simultaneously active. Indeed, different models of sparse coding, coupled with Hebbian learning and homeostasis, have been proposed that successfully match the observed emergent response. However, the specific role of homeostasis in learning such sparse representations is still largely unknown. By quantitatively assessing the efficiency of the neural representation during learning, we derive a cooperative homeostasis mechanism that optimally tunes the competition between neurons within the sparse coding algorithm. We apply this homeostasis while learning small patches taken from natural images and compare its efficiency with state-of-the-art algorithms. Results show that while different sparse coding algorithms give similar coding results, the homeostasis provides an optimal balance for the representation of natural images within the population of neurons. Competition in sparse coding is optimized when it is fair. By contributing to optimizing statistical competition across neurons, homeostasis is crucial in providing a more efficient solution to the emergence of independent components.},
    annote = {Posted Online March 17, 2010.},
    author = {Perrinet, Laurent U.},
    citeulike-article-id = {7158387},
    citeulike-linkout-0 = {http://invibe.net/LaurentPerrinet/Publications/Perrinet10shl},
    citeulike-linkout-1 = {http://dx.doi.org/10.1162/neco.2010.05-08-795},
    citeulike-linkout-2 = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2010.05-08-795},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/20235818},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=20235818},
    date-added = {2011-03-16 13:52:51},
    day = {17},
    doi = {10.1162/neco.2010.05-08-795},
    issn = {1530-888X},
    journal = {Neural Computation},
    keywords = {adaptive, assofield, bicv-motion, bicv-sparse, cell, coding, competition-optimized, cooperative, fields, hebbian, homeostasis, images, khoei13jpp, learning, matching, matching-pursuit, natural, natural-scenes, neural, of, over-complete, overcomplete\_dictionaries, perrinet10shl, perrinet11sfn, perrinet12pred, population, pursuit, receptive, sanz12jnp, simple, sparse, sparse\_coding, sparse\_hebbian\_learning, sparse\_spike\_coding, statistics, thesis, unsupervised, vacher14},
    month = jul,
    number = {7},
    pages = {1812--1836},
    pmid = {20235818},
    priority = {0},
    publisher = {MIT Press},
    title = {Role of Homeostasis in Learning Sparse Representations},
    url = {http://invibe.net/LaurentPerrinet/Publications/Perrinet10shl},
    volume = {22},
    year = {2010}
}

@article{Geisler01,
    abstract = {The human brain manages to correctly interpret almost every visual image it receives from the environment. Underlying this ability are contour grouping mechanisms that appropriately link local edge elements into global contours. Although a general view of how the brain achieves effective contour grouping has emerged, there have been a number of different specific proposals and few successes at quantitatively predicting performance. These previous proposals have been developed largely by intuition and computational trial and error. A more principled approach is to begin with an examination of the statistical properties of contours that exist in natural images, because it is these statistics that drove the evolution of the grouping mechanisms. Here we report measurements of both absolute and Bayesian edge co-occurrence statistics in natural images, as well as human performance for detecting natural-shaped contours in complex backgrounds. We find that contour detection performance is quantitatively predicted by a local grouping rule derived directly from the co-occurrence statistics, in combination with a very simple integration rule (a transitivity rule) that links the locally grouped contour elements into longer contours.},
    author = {Geisler, Wilson S. and Perry, J. S. and Super, B. J. and Gallogly, D. P.},
    citeulike-article-id = {604345},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0042-6989(00)00277-7},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6T0W-42HFNG3-4/2/c5710a9d62b9c949ca369de213c8ce5e},
    date-added = {2011-02-25 16:17:55},
    day = {1},
    doi = {10.1016/s0042-6989(00)00277-7},
    issn = {0042-6989},
    journal = {Vision {R}esearch},
    keywords = {association\_field, assofield, bicv-sparse, chevron, contour, edge\_co-occurrence, perrinet11sfn},
    month = mar,
    number = {6},
    pages = {711--24},
    priority = {5},
    title = {Edge co-occurence in natural images predicts contour grouping performance.},
    url = {http://dx.doi.org/10.1016/s0042-6989(00)00277-7},
    volume = {41},
    year = {2001}
}

@article{Lee03,
    abstract = {Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.},
    address = {Computer Science Department, Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, USA. tai@cs.cmu.edu},
    author = {Lee, Tai S. and Mumford, David},
    citeulike-article-id = {465822},
    citeulike-linkout-0 = {http://dx.doi.org/10.1364/JOSAA.20.001434},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/12868647},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/12868647},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=12868647},
    date-added = {2011-01-24 14:55:27},
    doi = {10.1364/JOSAA.20.001434},
    issn = {1520-8532},
    journal = {Journal of the Optical Society of America A},
    keywords = {area-v1, assofield, bayesian, belief\_propagation, free-energy, hierarchical\_model, particle-filter, perrinet11sfn, perrinetadamsfriston14, visual\_hierarchy},
    month = jul,
    number = {7},
    pages = {1434--1448},
    pmid = {12868647},
    priority = {5},
    title = {Hierarchical {Bayesian} inference in the visual cortex},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/12868647},
    volume = {20},
    year = {2003}
}

